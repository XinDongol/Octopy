{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GPU:  4\n",
      "PyTorch Version: 1.6.0+cu92\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import progress_bar\n",
    "\n",
    "\n",
    "from pprint import pprint as pp\n",
    "from scipy import linalg\n",
    "\n",
    "from utils import FlowLayout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('#GPU: ', torch.cuda.device_count())\n",
    "print('PyTorch Version:', torch.__version__)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toeplitz_1_ch(kernel, input_size):\n",
    "    # shapes\n",
    "    k_h, k_w = kernel.shape\n",
    "    i_h, i_w = input_size\n",
    "    o_h, o_w = i_h-k_h+1, i_w-k_w+1\n",
    "\n",
    "    # construct 1d conv toeplitz matrices for each row of the kernel\n",
    "    toeplitz = []\n",
    "    for r in range(k_h):\n",
    "        toeplitz.append(linalg.toeplitz(c=(kernel[r,0], *np.zeros(i_w-k_w)), r=(*kernel[r], *np.zeros(i_w-k_w))) ) \n",
    "\n",
    "    # construct toeplitz matrix of toeplitz matrices (just for padding=0)\n",
    "    h_blocks, w_blocks = o_h, i_h\n",
    "    h_block, w_block = toeplitz[0].shape\n",
    "\n",
    "    W_conv = np.zeros((h_blocks, h_block, w_blocks, w_block))\n",
    "\n",
    "    for i, B in enumerate(toeplitz):\n",
    "        for j in range(o_h):\n",
    "            W_conv[j, :, i+j, :] = B\n",
    "\n",
    "    W_conv.shape = (h_blocks*h_block, w_blocks*w_block)\n",
    "\n",
    "    return W_conv\n",
    "\n",
    "def toeplitz_mult_ch(kernel, input_size):\n",
    "    \"\"\"Compute toeplitz matrix for 2d conv with multiple in and out channels.\n",
    "    Args:\n",
    "        kernel: shape=(n_out, n_in, H_k, W_k)\n",
    "        input_size: (n_in, H_i, W_i)\"\"\"\n",
    "\n",
    "    kernel_size = kernel.shape\n",
    "    output_size = (kernel_size[0], input_size[1] - (kernel_size[2]-1), input_size[2] - (kernel_size[3]-1))\n",
    "    print('==> output_size', output_size)\n",
    "    T = np.zeros((output_size[0], int(np.prod(output_size[1:])), input_size[0], int(np.prod(input_size[1:]))))\n",
    "    print('==> T', T.shape)\n",
    "\n",
    "    for i,ks in enumerate(kernel):  # loop over output channel\n",
    "        for j,k in enumerate(ks):  # loop over input channel\n",
    "            T_k = toeplitz_1_ch(k, input_size[1:])\n",
    "            T[i, :, j, :] = T_k\n",
    "\n",
    "    T.shape = (np.prod(output_size), np.prod(input_size))\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InvConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InvConv, self).__init__()\n",
    "        self.if_init = False\n",
    "\n",
    "    def init_layer(self, old_layer):\n",
    "        self.old_weight = old_layer.weight.detach().cpu().clone().numpy()\n",
    "        self.inp_padding = old_layer.padding\n",
    "        \n",
    "        self.inp_size = list(old_layer.inp_size)[1:] # inp_size was obtained by hook\n",
    "        \n",
    "        \n",
    "        if old_layer.padding[-1]>0:\n",
    "            self.inp_size[-1] += 2*old_layer.padding[-1]\n",
    "        if old_layer.padding[-2]>0:\n",
    "            self.inp_size[-2] += 2*old_layer.padding[-2]\n",
    "            \n",
    "        print('inp_size:', self.inp_size)\n",
    "        print('old weight', self.old_weight.shape)\n",
    "        self.old_weight_matrix = toeplitz_mult_ch(\n",
    "            self.old_weight, self.inp_size)\n",
    "        self.old_weight_matrix = torch.tensor(self.old_weight_matrix).float()\n",
    "        \n",
    "        # self.inv_old_weight_matrix = self.old_weight_matrix.t()\n",
    "        self.inv_old_weight_matrix = torch.pinverse(self.old_weight_matrix)\n",
    "        \n",
    "        \n",
    "        self.if_init = True\n",
    "        \n",
    "    def forward(self, y, if_inv=True):\n",
    "        '''\n",
    "        Problem: \n",
    "            1. the converted weight matrix is super large. This matrix may consum ~150G memory. Please do NOT use cuda. \n",
    "        '''\n",
    "        \n",
    "        assert self.if_init\n",
    "\n",
    "        # remember to transpose the old_weight_matrix\n",
    "        self.old_weight_matrix = self.old_weight_matrix.to(y.device)\n",
    "            \n",
    "        if if_inv:\n",
    "            '''\n",
    "            inversion of convolution\n",
    "            '''\n",
    "            y = y.contiguous()\n",
    "            out = torch.matmul(self.inv_old_weight_matrix[None,:,:], y.view(y.size(0), -1)[:,:,None])\n",
    "\n",
    "            # reshape the output\n",
    "            out = out.view([out.size(0)] + self.inp_size)\n",
    "\n",
    "            # un-padding\n",
    "            if self.inp_padding[0] == 0 and self.inp_padding[1]==0:\n",
    "                out_unpadding = out\n",
    "            else:\n",
    "                out_unpadding = out[:,:,self.inp_padding[0]:-self.inp_padding[0],self.inp_padding[1]:-self.inp_padding[1]]\n",
    "\n",
    "            return out_unpadding\n",
    "        else:\n",
    "            '''\n",
    "            standard convolution. However, we implement the convolution with pure matrix(weights)-vector(input) multiplication.\n",
    "            \n",
    "            '''\n",
    "            x = y\n",
    "            x_pad = F.pad(x, pad=[self.inp_padding[0],self.inp_padding[0],self.inp_padding[1],self.inp_padding[1]])\n",
    "            print('### x_pad', x_pad.view(x_pad.size(0), -1)[:,:,None].size())\n",
    "            out = torch.matmul(self.old_weight_matrix[None,:,:], x_pad.view(x_pad.size(0), -1)[:,:,None])\n",
    "            # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv#torch.nn.Conv2d\n",
    "            out_size = int( (self.inp_size[-1] - 1 * (self.old_weight.shape[-1] -1) - 1)  / 1. + 1)\n",
    "            out = out.view([out.size(0), self.old_weight.shape[0]]+[out_size]*2)\n",
    "            return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x, out_idx=False):\n",
    "        # out = self.features(x)\n",
    "        out = self.features[0](x)\n",
    "        out = self.features[1](out)\n",
    "        out = self.features[2](out)\n",
    "        out, idx03 = self.features[3](out)\n",
    "        out = self.features[4](out)\n",
    "        out = self.features[5](out)\n",
    "        out = self.features[6](out)\n",
    "        out, idx07 = self.features[7](out)\n",
    "        out = self.features[8](out)\n",
    "        out = self.features[9](out)\n",
    "        out = self.features[10](out)\n",
    "        out = self.features[11](out)\n",
    "        out = self.features[12](out)\n",
    "        out = self.features[13](out)\n",
    "        out, idx14 = self.features[14](out)\n",
    "        out = self.features[15](out)\n",
    "        out = self.features[16](out)\n",
    "        out = self.features[17](out)\n",
    "        out = self.features[18](out)\n",
    "        out = self.features[19](out)\n",
    "        out = self.features[20](out)\n",
    "        out, idx21 = self.features[21](out)\n",
    "        out = self.features[22](out)\n",
    "        out = self.features[23](out)\n",
    "        out = self.features[24](out)\n",
    "        out = self.features[25](out)\n",
    "        out = self.features[26](out)\n",
    "        out = self.features[27](out)\n",
    "        out, idx28 = self.features[28](out)\n",
    "        out = self.features[29](out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        if out_idx:\n",
    "            return out, (idx03, idx07, idx14, idx21, idx28)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=False)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Preparing data..\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='/dev/shm', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='/dev/shm', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [================================================================>]  Step: 25ms | Tot: 9s223ms | Loss: 0.466 | Acc: 89.690% (8969/10000) 157/157 \n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "best_acc = 0\n",
    "\n",
    "net = VGG('VGG11').to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# if args.resume:\n",
    "#     # Load checkpoint.\n",
    "#     print('==> Resuming from checkpoint..')\n",
    "#     assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "#     checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "#     net.load_state_dict(checkpoint['net'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']\n",
    "start_epoch = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=0, last_epoch=-1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        # state = {\n",
    "        #     'net': net.module.state_dict(),\n",
    "        #     'acc': acc,\n",
    "        #     'epoch': epoch,\n",
    "        # }\n",
    "        # torch.save(state, './cifar_vgg_11.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "# for epoch in range(start_epoch, start_epoch+epochs):\n",
    "#     train(epoch)\n",
    "#     test(epoch)\n",
    "#     scheduler.step()\n",
    "\n",
    "checkpoint = torch.load('./cifar_vgg_11.pth')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "\n",
    "        \n",
    "def InpSizeHook(module, input, output):\n",
    "    module.inp_size = input[0].size()\n",
    "    \n",
    "for n,m in net.named_modules():\n",
    "    if n!='' and n!='features':\n",
    "        m.register_forward_hook(InpSizeHook)\n",
    "    \n",
    "test(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0 || Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 3, 32, 32])\n",
      "features.1 || BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 64, 32, 32])\n",
      "features.2 || ReLU() || torch.Size([16, 64, 32, 32])\n",
      "features.3 || MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) || torch.Size([16, 64, 32, 32])\n",
      "features.4 || Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 64, 16, 16])\n",
      "features.5 || BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 128, 16, 16])\n",
      "features.6 || ReLU() || torch.Size([16, 128, 16, 16])\n",
      "features.7 || MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) || torch.Size([16, 128, 16, 16])\n",
      "features.8 || Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 128, 8, 8])\n",
      "features.9 || BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 256, 8, 8])\n",
      "features.10 || ReLU() || torch.Size([16, 256, 8, 8])\n",
      "features.11 || Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 256, 8, 8])\n",
      "features.12 || BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 256, 8, 8])\n",
      "features.13 || ReLU() || torch.Size([16, 256, 8, 8])\n",
      "features.14 || MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) || torch.Size([16, 256, 8, 8])\n",
      "features.15 || Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 256, 4, 4])\n",
      "features.16 || BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 512, 4, 4])\n",
      "features.17 || ReLU() || torch.Size([16, 512, 4, 4])\n",
      "features.18 || Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 512, 4, 4])\n",
      "features.19 || BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 512, 4, 4])\n",
      "features.20 || ReLU() || torch.Size([16, 512, 4, 4])\n",
      "features.21 || MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) || torch.Size([16, 512, 4, 4])\n",
      "features.22 || Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 512, 2, 2])\n",
      "features.23 || BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 512, 2, 2])\n",
      "features.24 || ReLU() || torch.Size([16, 512, 2, 2])\n",
      "features.25 || Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) || torch.Size([16, 512, 2, 2])\n",
      "features.26 || BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) || torch.Size([16, 512, 2, 2])\n",
      "features.27 || ReLU() || torch.Size([16, 512, 2, 2])\n",
      "features.28 || MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) || torch.Size([16, 512, 2, 2])\n",
      "features.29 || AvgPool2d(kernel_size=1, stride=1, padding=0) || torch.Size([16, 512, 1, 1])\n",
      "classifier || Linear(in_features=512, out_features=10, bias=True) || torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "for n,m in net.named_modules():\n",
    "    if n!='' and n!='features':\n",
    "        print(n,'||',m, '||',m.inp_size)\n",
    "        # print()\n",
    "        # if '9' in n:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvVGG(\n",
       "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (f01): BatchNorm2d(64, eps=1e-05, momentum=0.0, affine=True, track_running_stats=True)\n",
       "  (f00): InvConv()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class InvVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InvVGG, self).__init__()\n",
    "        # self.classifier = nn.Linear(10, 512)\n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # self.f26 = nn.BatchNorm2d(512)\n",
    "        # self.f25 = InvConv()\n",
    "        # self.f23 = nn.BatchNorm2d(512)\n",
    "        # self.f22 = InvConv()\n",
    "        # self.f19 = nn.BatchNorm2d(512)\n",
    "        # self.f18 = InvConv()\n",
    "        # self.f16 = nn.BatchNorm2d(512)\n",
    "        # self.f15 = InvConv()\n",
    "        # self.f12 = nn.BatchNorm2d(256)\n",
    "        # self.f11 = InvConv()\n",
    "        # self.f09 = nn.BatchNorm2d(256)\n",
    "        # self.f08 = InvConv()\n",
    "        # self.f05 = nn.BatchNorm2d(128)\n",
    "        # self.f04 = InvConv()\n",
    "        self.f01 = nn.BatchNorm2d(64, momentum=0.0)\n",
    "        self.f00 = InvConv()\n",
    "        \n",
    "    def forward(self, out, idx03, idx07, idx14, idx21, idx28):\n",
    "        # out = self.classifier(out)\n",
    "        # out = out.view(out.size(0), 512, 1, 1)\n",
    "\n",
    "        # out = self.unpool(out, idx28)  # f 28, pool\n",
    "        # # print('out 28:', out.size())\n",
    "        # out = self.f26(out)            # f 26, bn\n",
    "        # # print('out 26:', out.size())\n",
    "        # out = self.f25(out)            # f 25, conv\n",
    "        # out = self.f23(out)              # f 23, bn\n",
    "        # out = self.f22(out)              # f 22, conv\n",
    "        # out = self.unpool(out, idx21)  # f 21, pool\n",
    "        # out = self.f19(out)            # f 19, bn\n",
    "        # out = self.f18(out)            # f 18, conv\n",
    "        # out = self.f16(out)            # f 16, bn\n",
    "        # out = self.f15(out)            # f 15, conv\n",
    "        # out = self.unpool(out, idx14)  # f 14, pool\n",
    "        # out = self.f12(out)            # f 12, bn\n",
    "        # out = self.f11(out)            # f 11, conv\n",
    "        # out = self.f09(out)            # f 09, bn\n",
    "        # out = self.f08(out)            # f 08, conv\n",
    "        # out = self.unpool(out, idx07)  # f 07, pool\n",
    "        # out = self.f05(out)            # f 05, bn\n",
    "        # out = self.f04(out)            # f 04, conv\n",
    "        out = self.unpool(out, idx03)  # f 03, pool\n",
    "        out = self.f01(out)            # f 01, bn\n",
    "        out = self.f00(out)            # f 00, conv\n",
    "        \n",
    "        return out\n",
    "    \n",
    "inv_net = InvVGG()\n",
    "inv_net.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_size: [3, 34, 34]\n",
      "old weight (64, 3, 3, 3)\n",
      "==> output_size (64, 32, 32)\n",
      "==> T (64, 1024, 3, 1156)\n"
     ]
    }
   ],
   "source": [
    "# conv\n",
    "# inv_net.f25.init_layer(net.features[25])\n",
    "# inv_net.f22.init_layer(net.features[22])\n",
    "# inv_net.f18.init_layer(net.features[18])\n",
    "# inv_net.f15.init_layer(net.features[15])\n",
    "# inv_net.f11.init_layer(net.features[11])\n",
    "# inv_net.f08.init_layer(net.features[8])\n",
    "# inv_net.f04.init_layer(net.features[4])\n",
    "inv_net.f00.init_layer(net.features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_bn(inv_bn, old_bn):\n",
    "#     inv_bn.bias.data = old_bn.running_mean.cpu()\n",
    "#     inv_bn.weight.data = torch.sqrt(old_bn.running_var.cpu()+1e-8)\n",
    "\n",
    "def update_bn(inv_bn, old_bn):\n",
    "    inv_bn.bias.data = old_bn.running_mean.cpu().data\n",
    "    inv_bn.weight.data = torch.sqrt(old_bn.running_var.cpu()+1e-8).data\n",
    "    inv_bn.running_mean.data = old_bn.bias.cpu().data\n",
    "    inv_bn.running_var.data  = (old_bn.weight.cpu()**2).data\n",
    "\n",
    "# bn\n",
    "update_bn(inv_net.f01, net.features[1])\n",
    "# update_bn(inv_net.f05, net.features[5])\n",
    "# update_bn(inv_net.f09, net.features[9])\n",
    "# update_bn(inv_net.f12, net.features[12])\n",
    "# update_bn(inv_net.f16, net.features[16])\n",
    "# update_bn(inv_net.f19, net.features[19])\n",
    "# update_bn(inv_net.f23, net.features[23])\n",
    "# update_bn(inv_net.f26, net.features[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64, 16, 16])\n",
      "torch.Size([256, 3, 32, 32])\n",
      "tensor([[[[-0.3353]],\n",
      "\n",
      "         [[-0.2991]],\n",
      "\n",
      "         [[-0.2297]]]])\n",
      "tensor([[[[0.6397]],\n",
      "\n",
      "         [[0.6506]],\n",
      "\n",
      "         [[0.6750]]]])\n"
     ]
    }
   ],
   "source": [
    "# for class 0\n",
    "saved = torch.load('/project/kung/xin/cifar_vgg11_saved_model/c0.pth')\n",
    "\n",
    "\n",
    "out_features0 = saved['features.4'][0:256]\n",
    "print(out_features0.size())\n",
    "\n",
    "with torch.no_grad():\n",
    "    out, (idx03, idx07, idx14, idx21, idx28) = net(saved['features.0'][0:256], True)\n",
    "    inverted_img = inv_net(out_features0, idx03, None, None, None, None)\n",
    "    print(inverted_img.size())\n",
    "\n",
    "mean = inverted_img.mean([0,2,3], keepdim=True)\n",
    "std  = inverted_img.std([0,2,3], unbiased=False, keepdim=True)\n",
    "print(mean)\n",
    "print(std)\n",
    "\n",
    "realmean = torch.tensor([-0.3295, -0.3372, -0.3112]).view(1,3,1,1)\n",
    "realstd  = torch.tensor([1.3969, 1.3923, 1.4135]).view(1,3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f195d844f98>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfYElEQVR4nO2da2yk5ZXn/6feqnKV7bLdtttu03caCJcmNKSXEDoBcpshzKySSJso+TBipWh6PkykjTT7AWWlTfZbdrXJKB9WkToTFGaVyYTZJBu0QjOD0LAQYICmw70hNGD64qbd7valbJfLdTn7wcWqYZ7/Y9O2yz28/5/Uavs5ft731FPvqbfq+dc5x9wdQogPP5mNdkAI0R4U7EKkBAW7EClBwS5ESlCwC5ESFOxCpITsaiab2Z0AfgggAfBX7v692N8n2cRzHbmwI/U6nVdrht3s6e/nJ2suUJMZf41zGJ/3AcffPeLFnCtGbJYbOZ9/8Me1NC9iy0Qem4WPahE/4ieLzLqIQ1r0XBf3vESPGJG42VpdzHKUy2VUKgvBA150sJtZAuB/APg8gJMAnjGzB9z9FTYn15HDzut2BW2bz03Qc50oh4P681/7Gvev8hq1ZbOd1OaeUFuSCT8pSeSJzLDgA7BokXNFnulYwHi2FhxvNvP8XPWI/80mtxUa1FbLhi+tpM4vuWZkHS3D/WgmkUBqhF/Ys85vLjDuozt/zPXI8xm9mSVhHzMRF5280P7dL35D56zmbfzNAI65+5vuvgjgbwF8cRXHE0KsI6sJ9q0ATlzw+8nWmBDiEmQ1n9lD7yX/xXsLMzsI4CAAZPOr2iIQQqyC1dzZTwLYfsHv2wCMvf+P3P2Qu+939/1Jln+mEUKsL6sJ9mcAXGlmu80sD+BrAB5YG7eEEGvNRb+vdve6mX0TwD9gSXq7191fjs3JeA4dC5uDtkqJz9uS7Q2OlzqO0TnlyU3cj06+zdkgu8gAkG+Gd8ELkZ3zWuTNTDOye5tp8l3fHN+YRtM7wn7wzXiUGgVqK3fNUFs9cqsoLobXsWnceaZ2ABF5CoAjsiBk19rr/DGjGVEFIu9OjT9lUakvSxQDRJQcIz7GRMNVfYh29wcBPLiaYwgh2oO+QSdESlCwC5ESFOxCpAQFuxApQcEuREpo61fakqSK3r63grZKnWtvix3h5I6ufFiSA4BzPdPUlm/yRJgEXJZrkoSFWsLlmLpHMuwiMlQj4U+NgWs8jXo1ON5s9tA5C11clxtIhqltvlrhtmx4HZ2sIQAUGhHhqMnndc5G1jEbtjVyfA2zEQkNde5jLiKvVSPXSIYIZrHrIxPxg59HCJEKFOxCpAQFuxApQcEuREpQsAuREtq6G19HNyYytwZtA8mbkXnhncyxY1N0TkdHF7U1u/gup5FkFwBokkSNWmSnOInVacvxeZlFaoJl+NOWJOGt5I4u7se5U+eprbLAa/kN9HA1pDkYfmyR6kxIktjahxUZAAAXGtAkCUUWyeJZDJdJXJoXqQuXRNSEJFJWyz38fEYuHTgrxRXZpNedXYiUoGAXIiUo2IVICQp2IVKCgl2IlKBgFyIltFV6K/ocrq89E7SNg9eMM6KF9O8epHMmZ+eprUDaSbXORi0J0V2ahYiUN8/PNTjE5cH6PNfeZhdmqa2ZLwbHkwUuXQ3l+GOeqPJzZSIaVRbhx2bgfmTA68IVqt3UVi7yJJNC92RwvH6en6vayeXG7CI/Vy1WZy4m6ZJ5kcp6IHlGUWlQd3YhUoKCXYiUoGAXIiUo2IVICQp2IVKCgl2IlLAq6c3MRgGUATQA1N19f+zv55Mu/K7740Hb0BRv5ZQtheWOZo5LP72LXFqpF3jqlUcyytzDYkgmIuVlyRwAmHwzLAsBQO/QZdSWdy5fNWthW51kwwFApsRlrR7jj60yFJb5AKBQCNcUbE7wTEWUuI+Lk6eorf/Vk9Q2s2172DDAZc+uBW5r5Hhtw6bz9fBY1p6HZbmYjNYgtfxibbLWQmf/tLtPrMFxhBDriN7GC5ESVhvsDuAfzexZMzu4Fg4JIdaH1b6NP+DuY2Y2BOAhM3vV3R+98A9aLwIHASBb4PXahRDry6ru7O4+1vp/HMCvAdwc+JtD7r7f3fcn+XDvcCHE+nPRwW5mXWZWevdnAH8A4KW1ckwIsbas5m38MIBf29JWfxbA37j738cmdDbmcONcOOutXOIy2sRk2M2OubN0zqkCz07qa3BZLtuMyFokO8zm+Gtmjqs4OH/0BLXVX3+N2jZ9dB+1VbNEr4nIgw2EW0YBwNkclylrr/G1mu0OS1Qj24bonF1T56ht/Az3sTvHC18OPv16cHw6UqSysJ+3w5rN8nenXo8UFyXFSgHALHytWjTvjcmUkcy7yNGiuPubAG642PlCiPYi6U2IlKBgFyIlKNiFSAkKdiFSgoJdiJTQ1oKTc0k3Dnd9ImjbVn6Fzss0wjLDTCQ7qWc6UuCvnxdz9AyX7HLNsKyRdPKijOUm13g2f+JKarNjPJOr1s0lR2uGv6XYXOAS2pbLdlBbX4PLa+f6eJbaudfCRRvPTfO1GnTuY/XKy6mtZLxA5NCePcHx3y7wr4TkGyRTDkAzEjL1bCTjzCOyHGvbFrsV18NStUUKpurOLkRKULALkRIU7EKkBAW7EClBwS5ESmjrbnxXs4ybK48GbWPJAJ2XI172DPfROVMdY9TWsRCujwYAlo8kH5CXxiZ4Ek+pWaG2U2M8qWJgB9+p79myjdrqr44Gx98AT7opvsbbaA19itt8/GVqy+wNbzFft4mvfdIYprbc+bepDQ2eCDN/9c7geOk1/jyXs5EWVXV+fywan9eI3FeppsE31tFMwufySCKM7uxCpAQFuxApQcEuREpQsAuREhTsQqQEBbsQKaGt0tt8phuHO28N2rae4lLZXF9YTuis8qSKhSqXY5IsT7iIKCtIPCySuHHpzTu4rblYprb/+zyXyvqnuCZz4IqwLLcz4esxMfoWtZ19i7fl+sgCl8p6h8Ptq4qRxJp6D5eNcqVwQgsA9JBEKQAYG5sJjpfnuR+9WV6DbjEfqVHYjFw8Gf7Y2LNpzo+XaYalw4hapzu7EGlBwS5ESlCwC5ESFOxCpAQFuxApQcEuREpYVnozs3sB/DGAcXff2xrrB/ALALsAjAL4qrtPLneszsY8PjZ7OGib3MFFg96pcObVQvUdOmcmx+uq9TS5VGNE0gCAJmnhY01e027izGlq69i8m9o+l+FS2ZNvh1saAcCR0fCaDF9/DZ1z2dXd1FZ9q0htJ2pnqK3x9vngeH8flyI7z/K2XLaTP2cTVX7Majks6Q6UuBRWr3Jp1rPcj1jROK/z2oZO8t64h0DGWeiurgbdTwHc+b6xewA87O5XAni49bsQ4hJm2WBv9Vt//8v0FwHc1/r5PgBfWmO/hBBrzMV+Zh9299MA0Pqft+YUQlwSrPvXZc3sIICDANDZ0dZv5wohLuBi7+xnzGwEAFr/j7M/dPdD7r7f3fd3ZPkmhRBifbnYYH8AwN2tn+8G8Ju1cUcIsV6sRHr7OYA7AAya2UkA3wHwPQD3m9k3ABwH8JWVnGwu6cIzXR8P2nZOvcrn1cLZYcfmeUugXjvHHSESGgAgH2nhUw8v12KNF47sqXM5qXMnF1cG+nkLous387ZXzVLYx+IML3z58rO81dSWLR+htr6t4cw2AMh5OCNx/lS4PRUA1LPhDDUAyLzB5c2+oX5qy/aOBMcnp7hs2Mzzd6DsGgCADLiPjcibWq8zSTci813Em+Rlg93dv05Mn/3gpxNCbBT6Bp0QKUHBLkRKULALkRIU7EKkBAW7ECmhzb3eZnFz5cmgbQy8p1i3heWTT2+fp3Nef5MXDawXueSVLfdQ26JPBMdzQzwz7LqrPk1tj9cWqO3Y4ivU9rFeLoflNk0Hx3uHeC+97gn+ml8e54UvT09xGa0zCcthIzfwDLXCPJcp55vhnm0A8NjzZ6ktvzn8XF/DT4XmIr+umuAya63Or7lMpOCkJ+EsO0/482I0642jO7sQKUHBLkRKULALkRIU7EKkBAW7EClBwS5ESmhzr7dOPFe8KWjrrfPMq8JsOPvnxDSXQSaKvI9an/F+XbM9XA7bWgxLbMO9vJjj4Wd4Ucxy9hS1bRkJ92wDgMICz3rzjqng+PkCrwe6c6qP2s7t4bLiZlrFABibnQuOH3k07B8AbN/Ln5dtZO0BYO44X8fxt8JrtWkfzyrsrXEfC/1haRMA5hb5vTMHnnVIi0fWuVyXcV4Ylc75wDOEEP8qUbALkRIU7EKkBAW7EClBwS5ESmjrbnyxUcF10y8EbdPOi2qdK4Z346sJT4Do7+A79R0Nvpvd9/xr1JbdfXVw/IHpUTqnu1Slto+N8OSf+sMPUdt4H9+p37H5o8HxmQxPQBnMhnfOASC3kz8vhZ08aeiTHeH7yJPH+f3lxV/z7f2Fm3lyyp5buB/H/im8i784xpN4Hu/hz9mBMrf1Rur8lbdwlSdL2ld5hmfrNOpMuYjs4FOLEOJDhYJdiJSgYBciJSjYhUgJCnYhUoKCXYiUsJL2T/cC+GMA4+6+tzX2XQB/CuBd7evb7v7gcseqJEU8v+n6oG1o/jidNzgVlhMqJV5XrXM0XC8OACpjvMVT9+wotU0/H25RVdt9I53Td8u/pbZNZ7icNDH8MWrrOsDln1wSlhy31rg8NTnAk0y6n3mb2uqDXLKb6QvXjPvCFi4nDX6Bn+vZE7w9WLa5i9o+8e82B8d//9gROmd69Apqe2eYt2TaEz4VACCDcJ05AGjmSO26Gj9XLgknwkQam63ozv5TAHcGxv/S3fe1/i0b6EKIjWXZYHf3RwGcb4MvQoh1ZDWf2b9pZi+Y2b1mtmnNPBJCrAsXG+w/ArAHwD4ApwF8n/2hmR00s8NmdrixyD9rCiHWl4sKdnc/4+4Nd28C+DGAmyN/e8jd97v7/iTPv68uhFhfLirYzd7TouXLAF5aG3eEEOvFSqS3nwO4A8CgmZ0E8B0Ad5jZPiyl2IwC+LOVnKzYmMe+qeeCtvM1ftc/n9sVHO87z+uBnXx1lNp2n+QSz6Ycr+2Vy+8Jjn/0CS6hZZ77K2or3BWWIQHgui/vorbRgdupLftKeC+1fPIROufIFJc9X/g9fx3fWumltuKO8PM5fBnXp64c5I/rU8OXUdtjT79ObTMdM8Hx6/+wm86ZfJBnPg50/htqO1vmUmRzfpTaenvC108lt0jnZGdJ1p7z+/eywe7uXw8M/2S5eUKISwt9g06IlKBgFyIlKNiFSAkKdiFSgoJdiJTQ9vZPz3btC9pGLCzJAcDQaLgdTzbHs7W2FLdS2+m9XF7LlHneUGUubNu78BQ/V57LU8890k9tIx28pVSl9DfUdvhIWDZ6fmKMztkxybMHd15zLbUlp96itufObwmOX/7GCTrnxeTH1Ja77Epqyy9w6bN8LNxWLOt/SOd8IZywBwB4K8dlymPn+PW4/Uyk/VMmnN2WixS+tAIJ3Uzk2qYWIcSHCgW7EClBwS5ESlCwC5ESFOxCpAQFuxApwdx5b6i1ZlNXh3/murAkNupchsoUwtltn7/939M5b514kdreLnMZ6qoi77+2bSKc1VTexKt2DR5nPbmAwwlXPhci2XeT53jxwoFsKTg+dMPldM6urbz3nUd6m80lXGoqzYf7tr2T5T3nqjO8/1qj8ga1jSf8npWbGgmOX3ENKfIIwHt5UcxqJby+AJDv4o9tOHcDteVy4ay90dfKdE5P/lxw/Kf3/2+cHj8b1Ih1ZxciJSjYhUgJCnYhUoKCXYiUoGAXIiW0NRGmknTipVJ4V3KL/Y7OmzoXrtWW4BSdMzkW3q0EgPrxcHIEAIxt4urE9A3h3daRx/lu9jOdC9R20niNsS3H+Y7wngM7qG371vBucU+5j86ZrfFd36Qjcj+o8h3tWme4Ztxwnu/u1xNeFy4zyGu/7SpyNeT8dDjJ5MxbfO27uTCELF9GDNs2atvRz+vT9fbvDo53RpLDXjweTsqqR/o/6c4uREpQsAuREhTsQqQEBbsQKUHBLkRKULALkRJW0v5pO4C/BrAFQBPAIXf/oZn1A/gFgF1YagH1VXefjB2r6BVcVz8atE3O8PY+WzvPBscXuq+mc64a5Akt1RLXJx4pc6lsy+/CfjRKfE4zF07EAIDt1/JWSFffwOvCeWckiaMcfv2eafI6bd7gl4HzfBwUc7PUVvewj9VKJGklxyW0xTqXIr3SQ23DxXDtt/xO3m5sphJuGQUAU2e5pNuY4nKeRY45urArOL596CY6Z38tHEd/n+PJOCu5s9cB/IW7XwPgFgB/bmbXArgHwMPufiWAh1u/CyEuUZYNdnc/7e5HWj+XARwFsBXAFwHc1/qz+wB8ab2cFEKsng/0md3MdgG4EcBTAIbd/TSw9IIAYGitnRNCrB0rDnYz6wbwSwDfcnf+AeRfzjtoZofN7HC1Fv7qohBi/VlRsJtZDkuB/jN3/1Vr+IyZjbTsIwCCpUnc/ZC773f3/R25ZC18FkJcBMsGu5kZlvqxH3X3H1xgegDA3a2f7wbwm7V3TwixVqwk6+0AgD8B8KLZ/0/D+TaA7wG438y+AeA4gK8sd6BKphOvFMNZb9sLL9N5U6fC2wFd5WN0zunNvFbYriavB3bX3BFqO1oKy4PFApd+rujhGXGNPi6TlCMZccVKpGZcIyxf1ZtcbszMRlKlOvi5mrXI5UPexGUS3gapCl6DLh+plZhLuOI7mQ9fB12Rj5SdJZ69dtZ4y6sT0+FacgAw9Sp/rvcXw/USxws30jl7d/xRcDyXv5/OWTbY3f23ANjV8Nnl5gshLg30DTohUoKCXYiUoGAXIiUo2IVICQp2IVJCWwtOFpsV7J0LywyTxr9wkx0Otzs6N8ErA5bqU9Q2nueFKrMJz6TbN0IKMyZcnqo0+etppsKz5boSnuWVGJevGvlwS6ZF51JTJvKan8vxVlNN45JdllQ+rEee53yDH89zXHqrWmStZsLzqrnItzkbPENwpINnMQ4Ncrn3xDj/0unhw+Hz7ejma/XIHWeC4+UmP4/u7EKkBAW7EClBwS5ESlCwC5ESFOxCpAQFuxApob293jJFvNQV7tu2dZ5nE5WzYamp2cklktoULyjYG8mrb+R4T665LMlcqvACkPk8l9eMHQ8AmrzSo0UywNzDjy0XKUSYi7zmLy5GMuIakceWJ3JYJPuu5pHMPPK4ACBZ4JfxooevEa/z9SgYlxunO7gtO8t71e3ZyrMYz9TC846/zeXj7D+E5ePaDI8J3dmFSAkKdiFSgoJdiJSgYBciJSjYhUgJbd2N72zO4/r5cI236UofnVecCScY9F7Ndz9nOnqpreEkoQVAZEMYuVp4hzyb5zv4jUhBXa/zXXxWww0AqsZ34zMI27KRNk4N8B3mXKT/Uy3P/Ugy4Xl11Pi56vze4xE/Ghk+z3LhJ9RqfIGrCX9c+cVI662I8jJu/Fotkapvm/fwZJ0zJHKTfCTxilqEEB8qFOxCpAQFuxApQcEuREpQsAuREhTsQqSEZaU3M9sO4K8BbAHQBHDI3X9oZt8F8KcAzrb+9Nvu/mDsWPOZIl4shhNhSoU36LzuhXfCvhU/zv3OnKA2b3AZpMO43MEknmqdL2M2G9HymlzyciJdAUAWPImj0SQJFwmXjDLOX/MbmUiyCyIyVDW8jh5Zj3qkXl8SSYRpZPg6JkT7TCLyZWytkOHzrM597Grydax3hJ/PmQb3Y3M9LC1nnV8bK9HZ6wD+wt2PmFkJwLNm9lDL9pfu/t9XcAwhxAazkl5vpwGcbv1cNrOjALaut2NCiLXlA31mN7NdAG4E8FRr6Jtm9oKZ3Wtmm9bYNyHEGrLiYDezbgC/BPAtd58B8CMAewDsw9Kd//tk3kEzO2xmhxuL1TVwWQhxMawo2M0sh6VA/5m7/woA3P2Muzd86UvLPwZwc2iuux9y9/3uvj/J8+oxQoj1ZdlgNzMD8BMAR939BxeMX9ga48sAXlp794QQa8VKduMPAPgTAC+a2XOtsW8D+LqZ7QPgAEYB/NlyB+pszOOGcjjr7Wx1gM4rz4cljfnqLJ3TbHKJpLPG5bVKP3/30TEdfm3M95+kc7KVbdSWdPOPNfPT4TZOAJAv8Ky9ykBYeinNRurWRVohJdVI+6cZLg01hkkttCneIqlr01lqm6rxPeFSk69Hbb4nOF4Z4jXhRnh3LUwlXDrMNfg6zs7ybL98gcisBb5WXg/L0cjw86xkN/63QDAHL6qpCyEuLfQNOiFSgoJdiJSgYBciJSjYhUgJCnYhUkJ72z8lRbzQsy9oG2hy+SrXCLfBGermstD4LM9AqkcSnnoLXFrxcn9wPD81TudMdI9QW9/MeWrLNXgRy02b91Bb5hjxf0u4XRAA5HE5tU2feYLaZnfwop4fWdgdHJ+c53Jddjs1oX+MS5Gz42PU1tgZlrXyE3wNOzv42k9FEuJiCY6DlU5qm03Cclm+xg+YzYZlOWvy6153diFSgoJdiJSgYBciJSjYhUgJCnYhUoKCXYiUYO4RHWqN6S/l/fM3DgdtU5PhcQCoDYfTkCaPd9E5PSUu5c3UuRxW6D1DbcnZcD+62sA5Oic3w8+V7eOS3ewil8NQP0ZNXfXwmszluSSTq/I0r9Imfn3MvnMVtTV2hTOeO0/x52yiwM9VqPFsxN5+LmFW3r4iOO5X8YKkyVtc8prsKlDbQAfPpFuIyGhdpHDn+R5+vOmz4Tljx0ZRnV8Inkx3diFSgoJdiJSgYBciJSjYhUgJCnYhUoKCXYiU0NastwUr4vX83qCtc4BnLnVOhMc3lXhfKyvxh1YYD2evAcDA4iS1jZW2BMf7WX81AFVwqalzmmeNNS1S2LCHH7O8OBgcH5rlvcbmSlz2XJjjRT17cqSoJIB6NdxPb6oQ9g8AdoWTGwEAcyO8mON8hWfEdXeQebM8fe1sgculW2r8uc4av3bm8/xxF6fDx8wvhItlAsDexXBm3qSy3oQQCnYhUoKCXYiUoGAXIiUo2IVICcvuxptZAcCjADpaf/+/3P07ZtYP4BcAdmGp/dNX3Z1vRwLI+yIuq48GbdUsb/1ju8OvSdVzfEe1u8Tr0+VyPAGlVuS7rT3zYR9znbxm2WI3b03U7IxsP0dqteVzfGe9uBjeIW+O8GSRZIbvdBf6eJLP7OxmauvKhtexFNnBX9zGffQZ3h5sUz/3cbonPK+U58/zpg5+GSddkR33uSFq29x1nNpmu8KqTG/kcc2Qdl6Nd/h1v5I7exXAZ9z9Biy1Z77TzG4BcA+Ah939SgAPt34XQlyiLBvsvsS7Ymuu9c8BfBHAfa3x+wB8aV08FEKsCSvtz560OriOA3jI3Z8CMOzupwGg9T9/DyOE2HBWFOzu3nD3fQC2AbjZzMJfgwtgZgfN7LCZHV6s8c8TQoj15QPtxrv7FIBHANwJ4IyZjQBA6//grpe7H3L3/e6+P59r67dzhRAXsGywm9lmM+tr/VwE8DkArwJ4AMDdrT+7G8Bv1stJIcTqWcmtdgTAfWaWYOnF4X53/z9m9iSA+83sGwCOA/jKcgdarOdxamJn0NZ3NjwOAO/sDCdjfPZlXpfs4c+F2+MAwO1P83mP37aJ2m59Olx/7InbeWLNrU9xCe2J28M17QDgk5F5j9/G57HzPXEHf1yfOMwTSZ64jSdwfOqf+eXz2O3h8x14LLIen46s4zO89tvjd/B5n3oy7OOjd3Ap78DTPMHqydu53Hjr05Hn7DN8/Q88G74ej1wTbgsFABWSoFSvkawxrCDY3f0FADcGxs8B+Oxy84UQlwb6Bp0QKUHBLkRKULALkRIU7EKkBAW7ECmhre2fzOwsgLdbvw4C4DpB+5Af70V+vJd/bX7sdPegPtjWYH/Pic0Ou/v+DTm5/JAfKfRDb+OFSAkKdiFSwkYG+6ENPPeFyI/3Ij/ey4fGjw37zC6EaC96Gy9EStiQYDezO83sNTM7ZmYbVrvOzEbN7EUze87MDrfxvPea2biZvXTBWL+ZPWRmr7f+52lS6+vHd83sVGtNnjOzu9rgx3Yz+yczO2pmL5vZf2iNt3VNIn60dU3MrGBmT5vZ8y0//ktrfHXr4e5t/QcgAfAGgMsB5AE8D+DadvvR8mUUwOAGnPc2ADcBeOmCsf8G4J7Wz/cA+K8b5Md3AfzHNq/HCICbWj+XAPwewLXtXpOIH21dEwAGoLv1cw7AUwBuWe16bMSd/WYAx9z9TXdfBPC3WCpemRrc/VEA76+b3PYCnsSPtuPup939SOvnMoCjALaizWsS8aOt+BJrXuR1I4J9K4ATF/x+EhuwoC0cwD+a2bNmdnCDfHiXS6mA5zfN7IXW2/x1/zhxIWa2C0v1Eza0qOn7/ADavCbrUeR1I4I91It4oySBA+5+E4AvAPhzM7ttg/y4lPgRgD1Y6hFwGsD323ViM+sG8EsA33L3mXaddwV+tH1NfBVFXhkbEewnAWy/4PdtAHhz9nXE3cda/48D+DWWPmJsFCsq4LneuPuZ1oXWBPBjtGlNzCyHpQD7mbv/qjXc9jUJ+bFRa9I69wcu8srYiGB/BsCVZrbbzPIAvoal4pVtxcy6zKz07s8A/gDAS/FZ68olUcDz3YupxZfRhjUxMwPwEwBH3f0HF5jauibMj3avyboVeW3XDuP7dhvvwtJO5xsA/tMG+XA5lpSA5wG83E4/APwcS28Ha1h6p/MNAANYaqP1euv//g3y438CeBHAC62La6QNfnwSSx/lXgDwXOvfXe1ek4gfbV0TAB8F8LvW+V4C8J9b46taD32DToiUoG/QCZESFOxCpAQFuxApQcEuREpQsAuREhTsQqQEBbsQKUHBLkRK+H8hKwijzeRwIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from di import denormalize\n",
    "img_idx = 1\n",
    "plt.figure()\n",
    "plt.imshow(denormalize(saved['features.0'][img_idx]).view(3,-1).T.view(32,32,3))\n",
    "plt.figure()\n",
    "plt.imshow(denormalize(inverted_img[img_idx]).reshape(3,-1).T.view(32,32,3).detach())\n",
    "plt.figure()\n",
    "plt.imshow(denormalize(((inverted_img[img_idx]-mean)/std)*realstd +realmean).view(3,-1).T.view(32,32,3).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# all_inp_l = []\n",
    "# for i in range(10):\n",
    "#     all_inp_l.append(torch.load('/project/kung/xin/cifar_vgg11_saved_model/c%d.pth'%i)['features.0'])\n",
    "# all_inp = torch.cat(all_inp_l)\n",
    "\n",
    "# stat_bsz = 128\n",
    "# realinp_dataset = torch.utils.data.TensorDataset(all_inp)\n",
    "# realinp_loader = torch.utils.data.DataLoader(realinp_dataset, batch_size=stat_bsz, shuffle=True)\n",
    "\n",
    "# mean_list = []\n",
    "# std_list = []\n",
    "# for data in realinp_loader:\n",
    "#     mean = data[0].mean([0,2,3])\n",
    "#     std  = data[0].std([0,2,3], unbiased=False)\n",
    "#     mean_list.append(mean)\n",
    "#     std_list.append(std)\n",
    "    \n",
    "# print(mean_list[0].size())\n",
    "\n",
    "# all_mean = torch.stack(mean_list).mean([0])\n",
    "# all_std  = torch.stack(std_list).mean([0])\n",
    "\n",
    "# print(all_mean)\n",
    "# print(all_std)\n",
    "\n",
    "# oPlot = FlowLayout() # create an empty FlowLayout\n",
    "# for i in range(3): \n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(5.9,5.9))\n",
    "#     cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "#     sns.histplot([t[i].item() for t in mean_list], stat='probability', kde=True)\n",
    "#     fig.tight_layout()\n",
    "#     # fig.suptitle('Output of Conv2d', fontsize=16)\n",
    "#     oPlot.add_plot(ax) \n",
    "#     plt.close() \n",
    "# oPlot.PassHtmlToCell()    \n",
    "\n",
    "\n",
    "# oPlot = FlowLayout() # create an empty FlowLayout\n",
    "# for i in range(3): \n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(5.9,5.9))\n",
    "#     cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "#     sns.histplot([t[i].item() for t in std_list], stat='probability', kde=True)\n",
    "#     fig.tight_layout()\n",
    "#     # fig.suptitle('Output of Conv2d', fontsize=16)\n",
    "#     oPlot.add_plot(ax) \n",
    "#     plt.close() \n",
    "# oPlot.PassHtmlToCell()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.8125\n",
      "Acc: 86.3281\n",
      "Acc: 86.9792\n",
      "Acc: 85.5469\n",
      "Acc: 86.2500\n",
      "Acc: 86.0677\n",
      "Acc: 86.0491\n",
      "Acc: 86.0352\n",
      "Acc: 86.0243\n",
      "Acc: 85.7812\n",
      "Acc: 85.7244\n",
      "Acc: 85.3516\n",
      "Acc: 85.5769\n",
      "Acc: 85.7143\n",
      "Acc: 85.8854\n",
      "Acc: 85.8887\n",
      "Acc: 85.5239\n",
      "Acc: 85.1128\n",
      "Acc: 85.1562\n",
      "Acc: 85.6250\n",
      "Acc: 85.4911\n",
      "Acc: 85.5824\n",
      "Acc: 85.4959\n",
      "Acc: 85.4818\n",
      "Acc: 85.5000\n",
      "Acc: 85.6070\n",
      "Acc: 85.6481\n",
      "Acc: 85.8259\n",
      "Acc: 85.7489\n",
      "Acc: 85.5990\n",
      "Acc: 85.5595\n",
      "Acc: 85.7178\n",
      "Acc: 85.7718\n",
      "Acc: 85.6388\n",
      "Acc: 85.6473\n",
      "Acc: 85.8073\n",
      "Acc: 85.7897\n",
      "Acc: 85.8964\n",
      "Acc: 85.9375\n",
      "Acc: 85.8203\n",
      "Acc: 86.0328\n",
      "Acc: 86.1607\n",
      "Acc: 86.2645\n",
      "Acc: 86.3991\n",
      "Acc: 86.4931\n",
      "Acc: 86.6338\n",
      "Acc: 86.6024\n",
      "Acc: 86.5560\n",
      "Acc: 86.6071\n",
      "Acc: 86.6719\n",
      "Acc: 86.6268\n",
      "Acc: 86.6286\n",
      "Acc: 86.6745\n",
      "Acc: 86.6319\n",
      "Acc: 86.6619\n",
      "Acc: 86.6350\n",
      "Acc: 86.6365\n",
      "Acc: 86.6649\n",
      "Acc: 86.7585\n",
      "Acc: 86.7839\n",
      "Acc: 86.8596\n",
      "Acc: 86.9078\n",
      "Acc: 86.9172\n",
      "Acc: 86.9019\n",
      "Acc: 86.8510\n",
      "Acc: 86.8134\n",
      "Acc: 86.7654\n",
      "Acc: 86.7073\n",
      "Acc: 86.6282\n",
      "Acc: 86.5625\n",
      "Acc: 86.5317\n",
      "Acc: 86.5343\n",
      "Acc: 86.5475\n",
      "Acc: 86.4759\n",
      "Acc: 86.4896\n",
      "Acc: 86.5132\n",
      "Acc: 86.4955\n",
      "Acc: 86.4784\n",
      "Acc: 86.4814\n",
      "Acc: 86.4648\n",
      "Acc: 86.4873\n",
      "Acc: 86.4806\n",
      "Acc: 86.5023\n",
      "Acc: 86.5234\n",
      "Acc: 86.5349\n",
      "Acc: 86.4644\n",
      "Acc: 86.4583\n",
      "Acc: 86.4790\n",
      "Acc: 86.4993\n",
      "Acc: 86.5191\n",
      "Acc: 86.5041\n",
      "Acc: 86.5065\n",
      "Acc: 86.4751\n",
      "Acc: 86.4860\n",
      "Acc: 86.4556\n",
      "Acc: 86.4583\n",
      "Acc: 86.4691\n",
      "Acc: 86.4477\n",
      "Acc: 86.4899\n",
      "Acc: 86.5078\n",
      "Acc: 86.5099\n",
      "Acc: 86.4966\n",
      "Acc: 86.4533\n",
      "Acc: 86.4258\n",
      "Acc: 86.3988\n",
      "Acc: 86.4092\n",
      "Acc: 86.3975\n",
      "Acc: 86.4005\n",
      "Acc: 86.3819\n",
      "Acc: 86.4205\n",
      "Acc: 86.4302\n",
      "Acc: 86.4537\n",
      "Acc: 86.4699\n",
      "Acc: 86.4241\n",
      "Acc: 86.3859\n",
      "Acc: 86.4426\n",
      "Acc: 86.4583\n",
      "Acc: 86.4274\n",
      "Acc: 86.4102\n",
      "Acc: 86.4193\n",
      "Acc: 86.3765\n",
      "Acc: 86.3986\n",
      "Acc: 86.3377\n",
      "Acc: 86.3344\n",
      "Acc: 86.3375\n",
      "Acc: 86.3405\n",
      "Acc: 86.3189\n",
      "Acc: 86.3159\n",
      "Acc: 86.3009\n",
      "Acc: 86.3101\n",
      "Acc: 86.2953\n",
      "Acc: 86.3163\n",
      "Acc: 86.3193\n",
      "Acc: 86.3106\n",
      "Acc: 86.3426\n",
      "Acc: 86.3339\n",
      "Acc: 86.3367\n",
      "Acc: 86.3281\n",
      "Acc: 86.3309\n",
      "Acc: 86.3504\n",
      "Acc: 86.3309\n",
      "Acc: 86.3281\n",
      "Acc: 86.3145\n",
      "Acc: 86.3336\n",
      "Acc: 86.3308\n",
      "Acc: 86.3014\n",
      "Acc: 86.3202\n",
      "Acc: 86.3281\n",
      "Acc: 86.3150\n",
      "Acc: 86.3385\n",
      "Acc: 86.3618\n",
      "Acc: 86.3641\n",
      "Acc: 86.3715\n",
      "Acc: 86.3687\n",
      "Acc: 86.3810\n",
      "Acc: 86.3582\n",
      "Acc: 86.3854\n",
      "Acc: 86.3825\n",
      "Acc: 86.3748\n",
      "Acc: 86.3916\n",
      "Acc: 86.3985\n",
      "Acc: 86.3860\n",
      "Acc: 86.3737\n",
      "Acc: 86.3996\n",
      "Acc: 86.4157\n",
      "Acc: 86.4223\n",
      "Acc: 86.4427\n",
      "Acc: 86.4165\n",
      "Acc: 86.4136\n",
      "Acc: 86.4200\n",
      "Acc: 86.3989\n",
      "Acc: 86.4235\n",
      "Acc: 86.3981\n",
      "Acc: 86.3955\n",
      "Acc: 86.3839\n",
      "Acc: 86.4036\n",
      "Acc: 86.3965\n",
      "Acc: 86.3632\n",
      "Acc: 86.3478\n",
      "Acc: 86.3455\n",
      "Acc: 86.3562\n",
      "Acc: 86.3281\n",
      "Acc: 86.3175\n",
      "Acc: 86.3069\n",
      "Acc: 86.2880\n",
      "Acc: 86.3071\n",
      "Acc: 86.2717\n",
      "Acc: 86.2783\n",
      "Acc: 86.3095\n",
      "Acc: 86.3281\n",
      "Acc: 86.3302\n",
      "Acc: 86.3281\n",
      "Acc: 86.3342\n",
      "Acc: 86.3281\n",
      "Acc: 86.3381\n",
      "Acc: 86.3441\n",
      "Acc: 86.3420\n",
      "Acc: 86.3715\n",
      "Acc: 86.3851\n",
      "Acc: 86.3867\n",
      "Acc: 86.3806\n",
      "Acc: 86.4016\n",
      "Acc: 86.3993\n",
      "Acc: 86.3664\n",
      "Acc: 86.3491\n",
      "Acc: 86.3547\n",
      "Acc: 86.3715\n",
      "Acc: 86.3732\n",
      "Acc: 86.3898\n",
      "Acc: 86.3951\n",
      "Acc: 86.3818\n",
      "Acc: 86.3797\n",
      "Acc: 86.3923\n",
      "Acc: 86.3683\n",
      "Acc: 86.3590\n",
      "Acc: 86.3534\n",
      "Acc: 86.3587\n",
      "Acc: 86.3747\n",
      "Acc: 86.3906\n",
      "Acc: 86.4062\n",
      "Acc: 86.3971\n",
      "Acc: 86.3668\n",
      "Acc: 86.3614\n",
      "Acc: 86.3491\n",
      "Acc: 86.3542\n",
      "Acc: 86.3592\n",
      "Acc: 86.3780\n",
      "Acc: 86.3727\n",
      "Acc: 86.3708\n",
      "Acc: 86.3519\n",
      "Acc: 86.3467\n",
      "Acc: 86.3416\n",
      "Acc: 86.3399\n",
      "Acc: 86.3482\n",
      "Acc: 86.3165\n",
      "Acc: 86.3248\n",
      "Acc: 86.3034\n",
      "Acc: 86.2920\n",
      "Acc: 86.3134\n",
      "Acc: 86.3346\n",
      "Acc: 86.3038\n",
      "Acc: 86.3152\n",
      "Acc: 86.3233\n",
      "Acc: 86.3249\n",
      "Acc: 86.3361\n",
      "Acc: 86.3631\n",
      "Acc: 86.3613\n",
      "Acc: 86.3596\n",
      "Acc: 86.3705\n",
      "Acc: 86.3688\n",
      "Acc: 86.3670\n",
      "Acc: 86.3529\n",
      "Acc: 86.3636\n",
      "Acc: 86.3743\n",
      "Acc: 86.3817\n",
      "Acc: 86.3892\n",
      "Acc: 86.4148\n",
      "Acc: 86.4069\n",
      "Acc: 86.3930\n",
      "Acc: 86.3822\n",
      "Acc: 86.3895\n",
      "Acc: 86.3729\n",
      "Acc: 86.3682\n",
      "Acc: 86.3814\n",
      "Acc: 86.4004\n",
      "Acc: 86.3957\n",
      "Acc: 86.3940\n",
      "Acc: 86.3952\n",
      "Acc: 86.3993\n",
      "Acc: 86.3976\n",
      "Acc: 86.4189\n",
      "Acc: 86.3971\n",
      "Acc: 86.4154\n",
      "Acc: 86.4080\n",
      "Acc: 86.4205\n",
      "Acc: 86.4159\n",
      "Acc: 86.4254\n",
      "Acc: 86.4124\n",
      "Acc: 86.4135\n",
      "Acc: 86.4007\n",
      "Acc: 86.4101\n",
      "Acc: 86.4195\n",
      "Acc: 86.4206\n",
      "Acc: 86.3886\n",
      "Acc: 86.3734\n",
      "Acc: 86.3828\n",
      "Acc: 86.3785\n",
      "Acc: 86.3959\n",
      "Acc: 86.3917\n",
      "Acc: 86.3901\n",
      "Acc: 86.3993\n",
      "Acc: 86.4084\n",
      "Acc: 86.3988\n",
      "Acc: 86.3999\n",
      "Acc: 86.4010\n",
      "Acc: 86.3994\n",
      "Acc: 86.3873\n",
      "Acc: 86.4068\n",
      "Acc: 86.4104\n",
      "Acc: 86.4036\n",
      "Acc: 86.4047\n",
      "Acc: 86.4109\n",
      "Acc: 86.3913\n",
      "Acc: 86.4078\n",
      "Acc: 86.3986\n",
      "Acc: 86.3971\n",
      "Acc: 86.4007\n",
      "Acc: 86.4068\n",
      "Acc: 86.4280\n",
      "Acc: 86.4340\n",
      "Acc: 86.4349\n",
      "Acc: 86.4433\n",
      "Acc: 86.4342\n",
      "Acc: 86.4127\n",
      "Acc: 86.4261\n",
      "Acc: 86.4245\n",
      "Acc: 86.4304\n",
      "Acc: 86.4141\n",
      "Acc: 86.4249\n",
      "Acc: 86.4331\n",
      "Acc: 86.4364\n",
      "Acc: 86.4446\n",
      "Acc: 86.4430\n",
      "Acc: 86.4487\n",
      "Acc: 86.4375\n",
      "Acc: 86.4623\n",
      "Acc: 86.4751\n",
      "Acc: 86.4663\n",
      "Acc: 86.4694\n",
      "Acc: 86.4796\n",
      "Acc: 86.4804\n",
      "Acc: 86.4952\n",
      "Acc: 86.4982\n",
      "Acc: 86.4942\n",
      "Acc: 86.4855\n",
      "Acc: 86.4793\n",
      "Acc: 86.4777\n",
      "Acc: 86.4853\n",
      "Acc: 86.4860\n",
      "Acc: 86.4890\n",
      "Acc: 86.4782\n",
      "Acc: 86.4789\n",
      "Acc: 86.4750\n",
      "Acc: 86.4916\n",
      "Acc: 86.4968\n",
      "Acc: 86.4952\n",
      "Acc: 86.5094\n",
      "Acc: 86.5122\n",
      "Acc: 86.5150\n",
      "Acc: 86.5089\n",
      "Acc: 86.5162\n",
      "Acc: 86.5146\n",
      "Acc: 86.5107\n",
      "Acc: 86.5290\n",
      "Acc: 86.5075\n",
      "Acc: 86.5037\n",
      "Acc: 86.5152\n",
      "Acc: 86.5071\n",
      "Acc: 86.5055\n",
      "Acc: 86.5148\n",
      "Acc: 86.5153\n",
      "Acc: 86.5180\n",
      "Acc: 86.5207\n",
      "Acc: 86.5063\n",
      "Acc: 86.5026\n",
      "Acc: 86.4989\n",
      "Acc: 86.4974\n",
      "Acc: 86.5022\n",
      "Acc: 86.5091\n",
      "Acc: 86.5097\n",
      "Acc: 86.4955\n",
      "Acc: 86.5066\n",
      "Acc: 86.4967\n",
      "Acc: 86.4869\n",
      "Acc: 86.4875\n",
      "Acc: 86.4756\n",
      "Acc: 86.4721\n",
      "Acc: 86.4645\n",
      "Acc: 86.4734\n",
      "Acc: 86.4638\n",
      "Acc: 86.4706\n",
      "Acc: 86.4815\n",
      "Acc: 86.4801\n",
      "Acc: 86.4787\n",
      "Acc: 86.4732\n",
      "Acc: 86.4739\n",
      "Acc: 86.4866\n",
      "Acc: 86.5013\n",
      "Acc: 86.5119\n",
      "Acc: 86.5044\n",
      "Acc: 86.5060\n"
     ]
    }
   ],
   "source": [
    "def normalize_to(inp, mean, std):\n",
    "    inp_mean = inp.mean([0,2,3], keepdim=True)\n",
    "    inp_std  = inp.std([0,2,3], unbiased=False, keepdim=True)\n",
    "    return ((inp-inp_mean)/inp_std)*std + mean\n",
    "\n",
    "\n",
    "all_f0out_l = []\n",
    "all_target_l = []\n",
    "all_inp_l = []\n",
    "for i in range(10):\n",
    "    all_f0out_l.append(torch.load('/project/kung/xin/cifar_vgg11_saved_model/c%d.pth'%i)['features.4'])\n",
    "    all_inp_l.append(torch.load('/project/kung/xin/cifar_vgg11_saved_model/c%d.pth'%i)['features.0'])\n",
    "    all_target_l.append(torch.load('/project/kung/xin/cifar_vgg11_saved_model/c%d.pth'%i)['target'])\n",
    "all_f0out = torch.cat(all_f0out_l)\n",
    "all_inp   = torch.cat(all_inp_l)\n",
    "all_target = torch.cat(all_target_l)\n",
    "\n",
    "stat_bsz = 128\n",
    "realinp_dataset = torch.utils.data.TensorDataset(all_f0out, all_inp, all_target)\n",
    "realinp_loader = torch.utils.data.DataLoader(realinp_dataset, batch_size=stat_bsz, shuffle=True)\n",
    "\n",
    "realmean = torch.tensor([-0.3295, -0.3372, -0.3112]).view(1,3,1,1)\n",
    "realstd  = torch.tensor([1.3969, 1.3923, 1.4135]).view(1,3,1,1)\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "inv_net.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (f0out, inp, targets) in enumerate(realinp_loader):\n",
    "        out, (idx03, idx07, idx14, idx21, idx28) = net(inp, True)\n",
    "        inverted_img = inv_net(f0out, idx03, None, None, None, None)\n",
    "\n",
    "\n",
    "        # input back\n",
    "        outputs = net(normalize_to(inverted_img, realmean, realstd))\n",
    "        # outputs = net(inverted_img)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        acc = 100.*correct/total\n",
    "        print('Acc: %.4f'%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-788ee363e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "oPlot = FlowLayout() # create an empty FlowLayout\n",
    "\n",
    "# Some fairly regular plotting from Matplotlib\n",
    "gX = np.linspace(-5,5,100) # just used in the plot example\n",
    "for i in range(3): # plot 10 charts\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5.9,5.9)) # same size plots\n",
    "                           # figsize=(3+i/3,2+i/4)) # different size plots\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(denormalize(saved['features.0'][img_idx])[i], ax=ax, cmap=cmap, square=True, cbar_kws={\"shrink\": .8}, center=0.)\n",
    "    fig.tight_layout()\n",
    "    # fig.suptitle('Output of Conv2d', fontsize=16)\n",
    "    oPlot.add_plot(ax) # pass it to the FlowLayout to save as an image\n",
    "    plt.close() # this gets rid of the plot so it doesn't appear in the cell\n",
    "\n",
    "\n",
    "oPlot.PassHtmlToCell()\n",
    "\n",
    "\n",
    "\n",
    "oPlot = FlowLayout() # create an empty FlowLayout\n",
    "\n",
    "# Some fairly regular plotting from Matplotlib\n",
    "gX = np.linspace(-5,5,100) # just used in the plot example\n",
    "for i in range(3): # plot 10 charts\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5.9,5.9)) # same size plots\n",
    "                           # figsize=(3+i/3,2+i/4)) # different size plots\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(denormalize(((inverted_img[img_idx]-mean)/std)*realstd +realmean)[0][i], ax=ax, cmap=cmap, square=True, cbar_kws={\"shrink\": .8}, center=0.)\n",
    "    fig.tight_layout()\n",
    "    # fig.suptitle('Output of Conv2d', fontsize=16)\n",
    "    oPlot.add_plot(ax) # pass it to the FlowLayout to save as an image\n",
    "    plt.close() # this gets rid of the plot so it doesn't appear in the cell\n",
    "\n",
    "\n",
    "oPlot.PassHtmlToCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_bn(inv_bn, old_bn):\n",
    "#     inv_bn.bias.data = old_bn.running_mean.cpu()\n",
    "#     inv_bn.weight.data = torch.sqrt(old_bn.running_var.cpu()+1e-8)\n",
    "\n",
    "# def update_bn(inv_bn, old_bn):\n",
    "#     inv_bn.bias.data = old_bn.running_mean.cpu()\n",
    "#     inv_bn.weight.data = torch.sqrt(old_bn.running_var.cpu()+1e-8)\n",
    "#     inv_bn.running_mean.data = old_bn.bias.cpu().data\n",
    "#     inv_bn.running_var.data  = (old_bn.weight.cpu()**2).data\n",
    "\n",
    "# # bn\n",
    "# update_bn(inv_net.f01, net.features[1])\n",
    "# update_bn(inv_net.f05, net.features[5])\n",
    "# update_bn(inv_net.f09, net.features[9])\n",
    "# update_bn(inv_net.f12, net.features[12])\n",
    "# update_bn(inv_net.f16, net.features[16])\n",
    "# update_bn(inv_net.f19, net.features[19])\n",
    "# update_bn(inv_net.f23, net.features[23])\n",
    "# update_bn(inv_net.f26, net.features[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc\n",
    "# inv_net.classifier.weight.data = net.classifier.weight.data.T.contiguous().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureHook():\n",
    "#     def __init__(self, module):\n",
    "#         self.hook = module.register_forward_hook(self.hook_fn)\n",
    "\n",
    "#     def hook_fn(self, module, input, output):\n",
    "#         self.r_feature = input[0]\n",
    "\n",
    "#     def close(self):\n",
    "#         self.hook.remove()\n",
    "        \n",
    "        \n",
    "# hook_dict = {}\n",
    "# for n, m in net.named_modules():\n",
    "#     if n!='' and n!='features':\n",
    "#         hook_dict[n] = FeatureHook(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.eval()\n",
    "# # inv_net.train()\n",
    "# inv_net.eval()\n",
    "\n",
    "\n",
    "# device='cpu'\n",
    "\n",
    "# root = '/project/kung/xin/cifar_vgg11_saved_model/gamma_beta_inverted_images/'\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, (data, target) in enumerate(trainloader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         output, out_idx = net(data, True)\n",
    "\n",
    "#         # real_features = {n:h.r_feature for n,h in hook_dict.items()}\n",
    "\n",
    "#         inv_input = inv_net(output, out_idx[0], out_idx[1], out_idx[2], out_idx[3], out_idx[4])\n",
    "\n",
    "#         # fake_output, fake_out_idx = net(inv_input, True)\n",
    "\n",
    "#         # fake_features = {n:h.r_feature for n,h in hook_dict.items()}\n",
    "\n",
    "#         # data_display = torch.cat((data,  inv_input), 0)\n",
    "#         # print(\"displaying original input-inverted input pairs\")\n",
    "#         # vutils.save_image(data_display,'vgg_bn_gammabeta.png', normalize=True, scale_each=True, nrow=int(8))\n",
    "\n",
    "#         torch.save({'real_inp':data, 'real_label':target, 'fake_inp':inv_input}, root+'b-%s.pth'%batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_bn_dict = {}\n",
    "\n",
    "# for n, m in net.named_modules():\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         all_bn_dict[n] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_bn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob, os\n",
    "# import torch\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from di import denormalize\n",
    "# import numpy as np\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# import io\n",
    "# import base64\n",
    "\n",
    "\n",
    "# class FlowLayout(object):\n",
    "#     ''' A class / object to display plots in a horizontal / flow layout below a cell '''\n",
    "#     def __init__(self):\n",
    "#         # string buffer for the HTML: initially some CSS; images to be appended\n",
    "#         self.sHtml =  \"\"\"\n",
    "#         <style>\n",
    "#         .floating-box {\n",
    "#         display: inline-block;\n",
    "#         margin: 1px;\n",
    "#         border: 1px solid #888888;  \n",
    "#         }\n",
    "#         </style>\n",
    "#         \"\"\"\n",
    "\n",
    "#     def add_plot(self, oAxes):\n",
    "#         ''' Saves a PNG representation of a Matplotlib Axes object '''\n",
    "#         Bio=io.BytesIO() # bytes buffer for the plot\n",
    "#         fig = oAxes.get_figure()\n",
    "#         fig.canvas.print_png(Bio) # make a png of the plot in the buffer\n",
    "\n",
    "#         # encode the bytes as string using base 64 \n",
    "#         sB64Img = base64.b64encode(Bio.getvalue()).decode()\n",
    "#         self.sHtml+= (\n",
    "#             '<div class=\"floating-box\">'+ \n",
    "#             '<img src=\"data:image/png;base64,{}\\n\">'.format(sB64Img)+\n",
    "#             '</div>')\n",
    "\n",
    "#     def PassHtmlToCell(self):\n",
    "#         ''' Final step - display the accumulated HTML '''\n",
    "#         display(HTML(self.sHtml))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# oPlot = FlowLayout() # create an empty FlowLayout\n",
    "\n",
    "# for layer_name in all_bn_dict.keys(): # plot 10 charts\n",
    "#     running_std = torch.sqrt(all_bn_dict[layer_name].running_var)\n",
    "#     running_mean = all_bn_dict[layer_name].running_mean\n",
    "\n",
    "#     real_std = real_features[layer_name].std([0, 2, 3], unbiased=False)\n",
    "#     real_mean = real_features[layer_name].mean([0, 2, 3])\n",
    "\n",
    "#     fake_std = fake_features[layer_name].std([0, 2, 3], unbiased=False)\n",
    "#     fake_mean = fake_features[layer_name].mean([0, 2, 3])\n",
    "    \n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(8,5.9))\n",
    "\n",
    "#     ax.plot(running_mean.detach(), label='running mean', linewidth=3, alpha=0.5)\n",
    "#     ax.plot(real_mean.detach(),    label='mean on real data', linewidth=3, alpha=0.5)\n",
    "#     ax.plot(fake_mean.detach(),    label='mean on inverted data', linewidth=3, alpha=0.5)\n",
    "#     ax.set_title('%s Certain Channel'%layer_name, fontsize=23)\n",
    "#     ax.set_xlabel('channel index')\n",
    "#     ax.legend(fontsize=20)\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "#     oPlot.add_plot(ax) # pass it to the FlowLayout to save as an image\n",
    "#     plt.close() # this gets rid of the plot so it doesn't appear in the cell\n",
    "\n",
    "\n",
    "# oPlot.PassHtmlToCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureHook():\n",
    "#     def __init__(self, module):\n",
    "#         self.hook = module.register_forward_hook(self.hook_fn)\n",
    "\n",
    "#     def hook_fn(self, module, input, output):\n",
    "#         self.r_feature = input[0]\n",
    "\n",
    "#     def close(self):\n",
    "#         self.hook.remove()\n",
    "        \n",
    "        \n",
    "# hook_dict = {}\n",
    "# for n, m in net.named_modules():\n",
    "#     if n!='' and n!='features':\n",
    "#         hook_dict[n] = FeatureHook(m)\n",
    "        \n",
    "# root_dir = '/project/kung/xin/cifar_vgg11_saved_model/'\n",
    "        \n",
    "# for class_idx in range(10):\n",
    "#     t = np.array(trainset.targets)\n",
    "#     indices = np.argwhere(t==class_idx).flatten().tolist()\n",
    "#     sub_set = torch.utils.data.Subset(trainset, indices)\n",
    "#     sub_loader = torch.utils.data.DataLoader(\n",
    "#         sub_set, batch_size=len(sub_set), shuffle=False, num_workers=8)\n",
    "#     for image, label in sub_loader:\n",
    "#         output = net(image)\n",
    "        \n",
    "#     save_dict = {n:h.r_feature for n, h in hook_dict.items()}\n",
    "#     save_dict['output'] = output\n",
    "    \n",
    "#     torch.save(save_dict, root_dir+'c'+str(class_idx)+'.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
