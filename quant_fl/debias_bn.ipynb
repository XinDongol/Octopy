{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Len of last client: 2500\n",
      "(Device 0) Train Loss: 0.977 | Train Acc: 64.760\n",
      "(Device 1) Train Loss: 0.926 | Train Acc: 66.400\n",
      "(Device 2) Train Loss: 0.939 | Train Acc: 66.600\n",
      "(Device 3) Train Loss: 0.949 | Train Acc: 66.800\n",
      "(Device 4) Train Loss: 0.928 | Train Acc: 67.560\n",
      "(Device 5) Train Loss: 0.920 | Train Acc: 67.960\n",
      "(Device 6) Train Loss: 1.015 | Train Acc: 63.000\n",
      "(Device 7) Train Loss: 0.972 | Train Acc: 65.840\n",
      "(Device 8) Train Loss: 0.944 | Train Acc: 65.960\n",
      "(Device 9) Train Loss: 0.908 | Train Acc: 67.360\n",
      "(Device 10) Train Loss: 0.894 | Train Acc: 69.080\n",
      "(Device 11) Train Loss: 0.892 | Train Acc: 68.280\n",
      "(Device 12) Train Loss: 0.947 | Train Acc: 65.880\n",
      "(Device 13) Train Loss: 0.940 | Train Acc: 65.440\n",
      "(Device 14) Train Loss: 0.983 | Train Acc: 65.880\n",
      "(Device 15) Train Loss: 0.932 | Train Acc: 65.760\n",
      "(Device 16) Train Loss: 0.927 | Train Acc: 67.360\n",
      "(Device 17) Train Loss: 0.907 | Train Acc: 67.440\n",
      "(Device 18) Train Loss: 0.907 | Train Acc: 68.040\n",
      "(Device 19) Train Loss: 0.942 | Train Acc: 65.960\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "import model\n",
    "import fl_data\n",
    "import quant\n",
    "import utils\n",
    "import agg\n",
    "from di import DeepInversionClass\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./test')\n",
    "nbit = 32\n",
    "rounds = 1\n",
    "\n",
    "num_devices = 20\n",
    "device_pct = 1.0\n",
    "\n",
    "local_epochs = 20\n",
    "local_lr = 0.01\n",
    "global_lr = 0.05\n",
    "\n",
    "# Using CIFAR-10 again as in Assignment 1\n",
    "# Load training data\n",
    "transform_train = transforms.Compose([                                   \n",
    "    transforms.RandomCrop(32, padding=4),                                       \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='/tmp', train=True, \n",
    "                                        download=True,\n",
    "                                        transform=transform_train)\n",
    "\n",
    "# Load testing data\n",
    "transform_test = transforms.Compose([                                           \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='/tmp', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False,\n",
    "                                         num_workers=2)\n",
    "\n",
    "\n",
    "# Using same ConvNet as in Assignment 1\n",
    "\n",
    "\n",
    "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
    "                  milestones=None, batch_size=128):\n",
    "    if milestones == None:\n",
    "        milestones = [25, 50, 75]\n",
    "\n",
    "    device_net = copy.deepcopy(net)\n",
    "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9,\n",
    "                                weight_decay=5e-4)\n",
    "    # optimizer = torch.optim.Adam(device_net.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                     milestones=milestones,\n",
    "                                                     gamma=0.1)\n",
    "    device_trainset = fl_data.DatasetSplit(trainset, data_idxs)\n",
    "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=2)\n",
    "    return {\n",
    "        'net': device_net,\n",
    "        'id': device_id,\n",
    "        'dataloader': device_trainloader, \n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "        'train_loss_tracker': [],\n",
    "        'train_acc_tracker': [],\n",
    "        'test_loss_tracker': [],\n",
    "        'test_acc_tracker': [],\n",
    "        'tb_writers': {'train_loss': utils.AutoStep(writer.add_scalar, 'client/%s/train_loss'%device_id),\n",
    "                       'train_acc': utils.AutoStep(writer.add_scalar, 'client/%s/train_acc'%device_id),\n",
    "                       'test_loss': utils.AutoStep(writer.add_scalar, 'client/%s/test_loss'%device_id),\n",
    "                       'test_acc' : utils.AutoStep(writer.add_scalar, 'client/%s/test_acc'%device_id)}\n",
    "        }\n",
    "  \n",
    "def train(epoch, device, tb=True):\n",
    "    device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        device['optimizer'].zero_grad()\n",
    "        outputs = device['net'](inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        device['optimizer'].step()\n",
    "        train_loss += loss.item()\n",
    "        device['train_loss_tracker'].append(loss.item())\n",
    "        loss = train_loss / (batch_idx + 1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        dev_id = device['id']\n",
    "        # print(f'\\r(Device {dev_id}/Epoch {epoch}) ' + \n",
    "        #                  f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
    "    device['train_acc_tracker'].append(acc)\n",
    "\n",
    "    if tb:\n",
    "        device['tb_writers']['train_loss'].write(loss)\n",
    "        device['tb_writers']['train_acc'].write(acc)\n",
    "    return loss, acc\n",
    "\n",
    "def test(epoch, device, tb=True):\n",
    "    device['net'].eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = device['net'](inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            device['test_loss_tracker'].append(loss.item())\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            loss = test_loss / (batch_idx + 1)\n",
    "            acc = 100.* correct / total\n",
    "    print(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
    "    acc = 100.*correct/total\n",
    "    device['test_acc_tracker'].append(acc)\n",
    "    \n",
    "    if tb:\n",
    "        device['tb_writers']['test_loss'].write(loss)\n",
    "        device['tb_writers']['test_acc'].write(acc)\n",
    "    return loss, acc\n",
    "    \n",
    "\n",
    "def get_devices_for_round(devices, device_pct):\n",
    "    '''\n",
    "    '''\n",
    "    assert device_pct>0 and device_pct<=1, 'device pct must be in the range of (0,1].'\n",
    "    num_devices_in_round = round(device_pct*len(devices))\n",
    "    device_idxs = np.random.permutation(len(devices))[:num_devices_in_round]\n",
    "    return [devices[i] for i in device_idxs]\n",
    "\n",
    "\n",
    "net = model.ConvNet().cuda()\n",
    "# net = model.CifarNet().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "data_idxs_dict = fl_data.uniform_random_split(trainset, num_devices)\n",
    "# deep copy net for each devices\n",
    "devices = [create_device(net, i, trainset, data_idxs_dict[i], lr=local_lr)\n",
    "           for i in range(num_devices)]\n",
    "\n",
    "w_avg = net.state_dict()\n",
    "## IID Federated Learning\n",
    "\n",
    "start_time = time.time()\n",
    "for round_num in range(rounds):\n",
    "    round_devices = get_devices_for_round(devices, device_pct)\n",
    "    # round_devices = [devices[1], devices[2]]\n",
    "    for round_device_idx, device in enumerate(round_devices):\n",
    "        for local_epoch in range(local_epochs):\n",
    "            local_loss, local_acc = train(local_epoch, device)\n",
    "        print(f'\\r(Device {round_device_idx}) ' + \n",
    "                        f'Train Loss: {local_loss:.3f} | Train Acc: {local_acc:.3f}')\n",
    "        # quant.quantize_model(device['net'], nbit)\n",
    "        # device['binary_diff'] = quant.sign_state_dict(agg.diff_model(old=w_avg, new=device['net']))\n",
    "\n",
    "    new_w_avg = agg.average_weights(round_devices) # average all in the state_dict\n",
    "    # w_binary_diff = agg.majority_vote(round_devices)\n",
    "    \n",
    "    # update the old avg\n",
    "    # w_avg = agg.apply_diff(old=w_avg, diff=w_binary_diff, lr=global_lr)\n",
    "\n",
    "    # for device in devices:\n",
    "    #     device['net'].load_state_dict(w_avg)\n",
    "    #     device['optimizer'].zero_grad()\n",
    "    #     device['optimizer'].step()\n",
    "    #     device['scheduler'].step()\n",
    "\n",
    "    # test accuracy after aggregation\n",
    "    # round_loss, round_acc = test(round_num, devices[0], tb=False)\n",
    "    # writer.add_scalar('round/loss', round_loss, round_num)\n",
    "    # writer.add_scalar('round/acc', round_acc, round_num)\n",
    "    # print('====> Round:%d, Acc:%.4f'%(round_num, round_acc))\n",
    "\n",
    "\n",
    "# total_time = time.time() - start_time\n",
    "# print('Total training time: {} seconds'.format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bn(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            print('Running Mean:', m.running_mean, 'Running Var:', m.running_var)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0744,  0.0036, -0.0306,  0.0272,  0.0002, -0.0280, -0.0287,  0.1029,\n",
      "        -0.0351,  0.1488, -0.0775, -0.0177, -0.0194, -0.0102, -0.0182, -0.0535,\n",
      "         0.0486,  0.0987,  0.0804, -0.0640,  0.0228,  0.0977, -0.0882,  0.0641,\n",
      "         0.0454,  0.0651,  0.0015, -0.0010,  0.0795, -0.0918,  0.0407,  0.1066],\n",
      "       device='cuda:0') tensor([0.5307, 0.6357, 0.2727, 0.1687, 0.6205, 0.3531, 0.4539, 0.4079, 0.2951,\n",
      "        0.6086, 0.2851, 0.8654, 0.2922, 0.1938, 0.2660, 0.6800, 0.3680, 0.4611,\n",
      "        0.2331, 0.4524, 0.7325, 0.6504, 0.4791, 0.3642, 0.3921, 0.4003, 0.3270,\n",
      "        0.7584, 0.3774, 0.3673, 0.1967, 0.3016], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(new_w_avg['model.0.1.running_mean'], new_w_avg['model.0.1.running_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 2.303 | Test Acc: 6.650\n",
      "\n",
      "Running Mean: tensor([-0.0744,  0.0036, -0.0306,  0.0272,  0.0002, -0.0280, -0.0287,  0.1029,\n",
      "        -0.0351,  0.1488, -0.0775, -0.0177, -0.0194, -0.0102, -0.0182, -0.0535,\n",
      "         0.0486,  0.0987,  0.0804, -0.0640,  0.0228,  0.0977, -0.0882,  0.0641,\n",
      "         0.0454,  0.0651,  0.0015, -0.0010,  0.0795, -0.0918,  0.0407,  0.1066],\n",
      "       device='cuda:0') Running Var: tensor([0.5307, 0.6357, 0.2727, 0.1687, 0.6205, 0.3531, 0.4539, 0.4079, 0.2951,\n",
      "        0.6086, 0.2851, 0.8654, 0.2922, 0.1938, 0.2660, 0.6800, 0.3680, 0.4611,\n",
      "        0.2331, 0.4524, 0.7325, 0.6504, 0.4791, 0.3642, 0.3921, 0.4003, 0.3270,\n",
      "        0.7584, 0.3774, 0.3673, 0.1967, 0.3016], device='cuda:0')\n",
      " | Test Loss: 2.465 | Test Acc: 27.880\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.4646538812902907, 27.88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_biasbn = copy.deepcopy(net)\n",
    "biasbn_device = {'net': net_biasbn, 'test_loss_tracker':[], 'test_acc_tracker':[]}\n",
    "test(0, biasbn_device, False)\n",
    "\n",
    "net_biasbn.load_state_dict(new_w_avg)\n",
    "biasbn_device = {'net': net_biasbn, 'test_loss_tracker':[], 'test_acc_tracker':[]}\n",
    "show_bn(biasbn_device['net'])\n",
    "test(0, biasbn_device, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Mean: tensor([-0.0744,  0.0036, -0.0306,  0.0272,  0.0002, -0.0280, -0.0287,  0.1029,\n",
      "        -0.0351,  0.1488, -0.0775, -0.0177, -0.0194, -0.0102, -0.0182, -0.0535,\n",
      "         0.0486,  0.0987,  0.0804, -0.0640,  0.0228,  0.0977, -0.0882,  0.0641,\n",
      "         0.0454,  0.0651,  0.0015, -0.0010,  0.0795, -0.0918,  0.0407,  0.1066],\n",
      "       device='cuda:0') Running Var: tensor([0.5307, 0.6357, 0.2727, 0.1687, 0.6205, 0.3531, 0.4539, 0.4079, 0.2951,\n",
      "        0.6086, 0.2851, 0.8654, 0.2922, 0.1938, 0.2660, 0.6800, 0.3680, 0.4611,\n",
      "        0.2331, 0.4524, 0.7325, 0.6504, 0.4791, 0.3642, 0.3921, 0.4003, 0.3270,\n",
      "        0.7584, 0.3774, 0.3673, 0.1967, 0.3016], device='cuda:0')\n",
      " | Test Loss: 2.465 | Test Acc: 27.880\n",
      "\n",
      "=====> Start Check, Loss: 2.464653881290, Acc: 27.880\n",
      "Debias finetune on Train| Epoch: 0 | Loss: 1.127963, Acc: 63.28\n",
      "Debias finetune on Train| Epoch: 0 | Loss: 1.294731, Acc: 54.46\n",
      "Debias finetune on Train| Epoch: 0 | Loss: 1.298319, Acc: 54.64\n",
      "Debias finetune on Train| Epoch: 0 | Loss: 1.295680, Acc: 54.72\n",
      "Running Mean: tensor([-0.0808,  0.0077, -0.0344,  0.0407,  0.0097, -0.0274, -0.0184,  0.1067,\n",
      "        -0.0400,  0.1572, -0.0755, -0.0156, -0.0219, -0.0042, -0.0249, -0.0528,\n",
      "         0.0571,  0.0986,  0.0824, -0.0618,  0.0226,  0.1000, -0.0927,  0.0630,\n",
      "         0.0509,  0.0697,  0.0014, -0.0078,  0.0856, -0.0932,  0.0436,  0.0988],\n",
      "       device='cuda:0') Running Var: tensor([0.5149, 0.6126, 0.2245, 0.1428, 0.5921, 0.2388, 0.4224, 0.3533, 0.2433,\n",
      "        0.5693, 0.2350, 0.8492, 0.2574, 0.1648, 0.2150, 0.6537, 0.3474, 0.3961,\n",
      "        0.2046, 0.3919, 0.7054, 0.6225, 0.4410, 0.3315, 0.3728, 0.3691, 0.2810,\n",
      "        0.7407, 0.3497, 0.2941, 0.1516, 0.2226], device='cuda:0')\n",
      " | Test Loss: 1.304 | Test Acc: 55.510\n",
      "\n",
      "=====> Epoch: 0, Loss: 1.304077251048, Acc: 55.510\n",
      "Debias finetune on Train| Epoch: 1 | Loss: 1.243194, Acc: 57.81\n",
      "Debias finetune on Train| Epoch: 1 | Loss: 1.308233, Acc: 54.30\n",
      "Debias finetune on Train| Epoch: 1 | Loss: 1.298642, Acc: 54.43\n",
      "Debias finetune on Train| Epoch: 1 | Loss: 1.301701, Acc: 54.25\n",
      "Running Mean: tensor([-0.0786,  0.0064, -0.0337,  0.0401,  0.0085, -0.0265, -0.0170,  0.1029,\n",
      "        -0.0376,  0.1534, -0.0725, -0.0142, -0.0221, -0.0045, -0.0236, -0.0535,\n",
      "         0.0545,  0.0962,  0.0808, -0.0597,  0.0250,  0.0962, -0.0893,  0.0620,\n",
      "         0.0500,  0.0665,  0.0007, -0.0093,  0.0831, -0.0917,  0.0435,  0.0959],\n",
      "       device='cuda:0') Running Var: tensor([0.5211, 0.6131, 0.2239, 0.1435, 0.6031, 0.2391, 0.4233, 0.3538, 0.2454,\n",
      "        0.5747, 0.2347, 0.8511, 0.2608, 0.1655, 0.2186, 0.6617, 0.3479, 0.3979,\n",
      "        0.2055, 0.3972, 0.7033, 0.6236, 0.4418, 0.3346, 0.3819, 0.3698, 0.2812,\n",
      "        0.7404, 0.3545, 0.2960, 0.1529, 0.2219], device='cuda:0')\n",
      " | Test Loss: 1.302 | Test Acc: 55.670\n",
      "\n",
      "=====> Epoch: 1, Loss: 1.302318204807, Acc: 55.670\n",
      "Debias finetune on Train| Epoch: 2 | Loss: 1.421554, Acc: 53.91\n",
      "Debias finetune on Train| Epoch: 2 | Loss: 1.297456, Acc: 54.10\n",
      "Debias finetune on Train| Epoch: 2 | Loss: 1.309171, Acc: 53.80\n",
      "Debias finetune on Train| Epoch: 2 | Loss: 1.299753, Acc: 54.19\n",
      "Running Mean: tensor([-0.0832,  0.0058, -0.0306,  0.0403,  0.0091, -0.0205, -0.0207,  0.1034,\n",
      "        -0.0376,  0.1482, -0.0745, -0.0152, -0.0233, -0.0045, -0.0172, -0.0460,\n",
      "         0.0513,  0.0928,  0.0811, -0.0634,  0.0199,  0.0998, -0.0852,  0.0660,\n",
      "         0.0514,  0.0695, -0.0018, -0.0082,  0.0799, -0.0894,  0.0416,  0.0968],\n",
      "       device='cuda:0') Running Var: tensor([0.5179, 0.6140, 0.2264, 0.1436, 0.5995, 0.2378, 0.4230, 0.3567, 0.2459,\n",
      "        0.5675, 0.2362, 0.8526, 0.2561, 0.1666, 0.2129, 0.6582, 0.3479, 0.3990,\n",
      "        0.2054, 0.3946, 0.7029, 0.6243, 0.4447, 0.3323, 0.3787, 0.3682, 0.2822,\n",
      "        0.7430, 0.3532, 0.2940, 0.1523, 0.2244], device='cuda:0')\n",
      " | Test Loss: 1.307 | Test Acc: 55.430\n",
      "\n",
      "=====> Epoch: 2, Loss: 1.306797406341, Acc: 55.430\n",
      "Debias finetune on Train| Epoch: 3 | Loss: 1.212269, Acc: 61.72\n",
      "Debias finetune on Train| Epoch: 3 | Loss: 1.307369, Acc: 54.34\n",
      "Debias finetune on Train| Epoch: 3 | Loss: 1.303174, Acc: 54.33\n",
      "Debias finetune on Train| Epoch: 3 | Loss: 1.305422, Acc: 54.27\n",
      "Running Mean: tensor([-0.0794,  0.0053, -0.0311,  0.0394,  0.0098, -0.0219, -0.0170,  0.0998,\n",
      "        -0.0364,  0.1475, -0.0714, -0.0142, -0.0222, -0.0047, -0.0200, -0.0476,\n",
      "         0.0506,  0.0920,  0.0795, -0.0588,  0.0241,  0.0963, -0.0837,  0.0611,\n",
      "         0.0498,  0.0657, -0.0026, -0.0087,  0.0788, -0.0897,  0.0423,  0.0937],\n",
      "       device='cuda:0') Running Var: tensor([0.5209, 0.6194, 0.2271, 0.1449, 0.6016, 0.2391, 0.4285, 0.3541, 0.2456,\n",
      "        0.5698, 0.2360, 0.8602, 0.2604, 0.1673, 0.2164, 0.6601, 0.3494, 0.3980,\n",
      "        0.2065, 0.3960, 0.7109, 0.6275, 0.4445, 0.3361, 0.3813, 0.3714, 0.2843,\n",
      "        0.7484, 0.3539, 0.2973, 0.1541, 0.2229], device='cuda:0')\n",
      " | Test Loss: 1.305 | Test Acc: 55.460\n",
      "\n",
      "=====> Epoch: 3, Loss: 1.305231370503, Acc: 55.460\n",
      "Debias finetune on Train| Epoch: 4 | Loss: 1.238348, Acc: 57.81\n",
      "Debias finetune on Train| Epoch: 4 | Loss: 1.300321, Acc: 54.29\n",
      "Debias finetune on Train| Epoch: 4 | Loss: 1.307697, Acc: 54.31\n",
      "Debias finetune on Train| Epoch: 4 | Loss: 1.302354, Acc: 54.49\n",
      "Running Mean: tensor([-0.0829,  0.0095, -0.0359,  0.0415,  0.0108, -0.0299, -0.0190,  0.1100,\n",
      "        -0.0424,  0.1643, -0.0784, -0.0173, -0.0220, -0.0045, -0.0279, -0.0550,\n",
      "         0.0607,  0.1022,  0.0850, -0.0630,  0.0227,  0.1039, -0.0975,  0.0636,\n",
      "         0.0526,  0.0724,  0.0014, -0.0063,  0.0894, -0.0966,  0.0456,  0.1021],\n",
      "       device='cuda:0') Running Var: tensor([0.5084, 0.6066, 0.2214, 0.1408, 0.5899, 0.2336, 0.4165, 0.3474, 0.2417,\n",
      "        0.5555, 0.2319, 0.8397, 0.2513, 0.1649, 0.2092, 0.6456, 0.3434, 0.3903,\n",
      "        0.2017, 0.3872, 0.6951, 0.6142, 0.4352, 0.3264, 0.3702, 0.3638, 0.2777,\n",
      "        0.7341, 0.3443, 0.2892, 0.1495, 0.2191], device='cuda:0')\n",
      " | Test Loss: 1.308 | Test Acc: 55.240\n",
      "\n",
      "=====> Epoch: 4, Loss: 1.308065664919, Acc: 55.240\n"
     ]
    }
   ],
   "source": [
    "net_debiasbn = copy.deepcopy(net)\n",
    "net_debiasbn.load_state_dict(new_w_avg)\n",
    "debiasbn_device = {'net': net_debiasbn, 'test_loss_tracker':[], 'test_acc_tracker':[]}\n",
    "show_bn(net_debiasbn)\n",
    "test_loss, test_acc = test(0, debiasbn_device, False)\n",
    "print('=====> Start Check, Loss: %.12f, Acc: %.3f'%(test_loss, test_acc))\n",
    "\n",
    "## Update the running mean and running variance\n",
    "\n",
    "overall_trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                 batch_size=128,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_workers=2)\n",
    "debias_epochs = 5\n",
    "\n",
    "\n",
    "for epoch_idx in range(debias_epochs):\n",
    "    debiasbn_device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(overall_trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = debiasbn_device['net'](inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "        loss = train_loss / (batch_idx + 1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        if batch_idx%100==0:\n",
    "            print('Debias finetune on Train| Epoch: %d | Loss: %.6f, Acc: %.2f'%(epoch_idx, loss, acc))\n",
    "    \n",
    "    show_bn(debiasbn_device['net'])\n",
    "    test_loss, test_acc = test(0, debiasbn_device, False)\n",
    "    print('=====> Epoch: %d, Loss: %.12f, Acc: %.3f'%(epoch_idx, test_loss, test_acc))\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bn_only(device, epoch=50):\n",
    "    device['random_model_bn_track'].train()  #! important: remember to change to train mode \n",
    "    with torch.no_grad():\n",
    "        for e in range(epoch):\n",
    "            train_loss, correct, total = 0, 0, 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                outputs = device['random_model_bn_track'](inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                train_loss += loss.item()\n",
    "                loss = train_loss / (batch_idx + 1)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                acc = 100. * correct / total\n",
    "                dev_id = device['id']\n",
    "            if e % 10==0:\n",
    "                print(f'\\rRandWei_BN_Track(Device {dev_id}/Epoch {e}) ' + \n",
    "                             f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.625e+00, R_cross: 0.000e+00, R_total: 1.626e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.990e+00, R_cross: 0.000e+00, R_total: 1.991e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 2.349e+00, R_cross: 0.000e+00, R_total: 2.350e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.513e+00, R_cross: 0.000e+00, R_total: 1.515e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.782e+00, R_cross: 0.000e+00, R_total: 1.784e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.276e+00, R_cross: 0.000e+00, R_total: 2.277e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.819e+00, R_cross: 0.000e+00, R_total: 1.821e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.572e+00, R_cross: 0.000e+00, R_total: 1.573e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.736e+00, R_cross: 0.000e+00, R_total: 1.737e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.596e+00, R_cross: 0.000e+00, R_total: 1.598e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.609e+00, R_cross: 0.000e+00, R_total: 1.610e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 3.016e+00, R_cross: 0.000e+00, R_total: 3.017e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.803e+00, R_cross: 0.000e+00, R_total: 1.805e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.978e+00, R_cross: 0.000e+00, R_total: 1.980e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 2.016e+00, R_cross: 0.000e+00, R_total: 2.018e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.577e+00, R_cross: 0.000e+00, R_total: 1.578e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.514e+00, R_cross: 0.000e+00, R_total: 1.516e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.130e+00, R_cross: 0.000e+00, R_total: 2.132e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.345e+00, R_cross: 0.000e+00, R_total: 1.347e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.314e+00, R_cross: 0.000e+00, R_total: 2.316e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.886e+00, R_cross: 0.000e+00, R_total: 1.888e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.021e+00, R_cross: 0.000e+00, R_total: 2.023e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.824e+00, R_cross: 0.000e+00, R_total: 1.826e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.472e+00, R_cross: 0.000e+00, R_total: 1.473e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.495e+00, R_cross: 0.000e+00, R_total: 1.496e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.786e+00, R_cross: 0.000e+00, R_total: 2.788e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 2.554e+00, R_cross: 0.000e+00, R_total: 2.556e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.613e+00, R_cross: 0.000e+00, R_total: 1.615e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.741e+00, R_cross: 0.000e+00, R_total: 1.743e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.344e+00, R_cross: 0.000e+00, R_total: 1.345e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 2.164e+00, R_cross: 0.000e+00, R_total: 2.166e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.905e+00, R_cross: 0.000e+00, R_total: 1.907e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.685e+00, R_cross: 0.000e+00, R_total: 1.687e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.483e+00, R_cross: 0.000e+00, R_total: 1.484e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 2.679e+00, R_cross: 0.000e+00, R_total: 2.680e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.023e+00, R_cross: 0.000e+00, R_total: 2.025e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 2.645e+00, R_cross: 0.000e+00, R_total: 2.647e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 1.659e+00, R_cross: 0.000e+00, R_total: 1.661e+01\n",
      "-------------------- 2000 ------------------\n",
      "R_feature: 1.372e+00, R_cross: 0.000e+00, R_total: 1.373e+01\n",
      "-------------------- 4000 ------------------\n",
      "R_feature: 2.188e+00, R_cross: 0.000e+00, R_total: 2.190e+01\n",
      "Running Mean: tensor([-0.0744,  0.0036, -0.0306,  0.0272,  0.0002, -0.0280, -0.0287,  0.1029,\n",
      "        -0.0351,  0.1488, -0.0775, -0.0177, -0.0194, -0.0102, -0.0182, -0.0535,\n",
      "         0.0486,  0.0987,  0.0804, -0.0640,  0.0228,  0.0977, -0.0882,  0.0641,\n",
      "         0.0454,  0.0651,  0.0015, -0.0010,  0.0795, -0.0918,  0.0407,  0.1066],\n",
      "       device='cuda:0') Running Var: tensor([0.5307, 0.6357, 0.2727, 0.1687, 0.6205, 0.3531, 0.4539, 0.4079, 0.2951,\n",
      "        0.6086, 0.2851, 0.8654, 0.2922, 0.1938, 0.2660, 0.6800, 0.3680, 0.4611,\n",
      "        0.2331, 0.4524, 0.7325, 0.6504, 0.4791, 0.3642, 0.3921, 0.4003, 0.3270,\n",
      "        0.7584, 0.3774, 0.3673, 0.1967, 0.3016], device='cuda:0')\n",
      " | Test Loss: 2.465 | Test Acc: 27.880\n",
      "\n",
      "=====> Start Check, Loss: 2.464653881290, Acc: 27.880\n",
      "Running Mean: tensor([-0.0748,  0.0040, -0.0309,  0.0286,  0.0005, -0.0280, -0.0279,  0.1026,\n",
      "        -0.0351,  0.1493, -0.0768, -0.0175, -0.0202, -0.0099, -0.0183, -0.0541,\n",
      "         0.0493,  0.0982,  0.0806, -0.0638,  0.0231,  0.0974, -0.0884,  0.0644,\n",
      "         0.0460,  0.0653,  0.0014, -0.0019,  0.0800, -0.0918,  0.0411,  0.1056],\n",
      "       device='cuda:0') Running Var: tensor([0.5260, 0.6306, 0.2672, 0.1713, 0.6114, 0.3424, 0.4476, 0.4043, 0.2908,\n",
      "        0.6011, 0.2815, 0.8574, 0.2904, 0.1951, 0.2622, 0.6715, 0.3655, 0.4530,\n",
      "        0.2313, 0.4510, 0.7224, 0.6429, 0.4764, 0.3565, 0.3893, 0.3985, 0.3220,\n",
      "        0.7555, 0.3771, 0.3612, 0.1957, 0.2968], device='cuda:0')\n",
      " | Test Loss: 2.266 | Test Acc: 31.600\n",
      "\n",
      "=====> Epoch: 0, Loss: 2.266333411012, Acc: 31.600\n",
      "Running Mean: tensor([-0.0751,  0.0044, -0.0310,  0.0299,  0.0008, -0.0279, -0.0271,  0.1024,\n",
      "        -0.0350,  0.1497, -0.0762, -0.0174, -0.0209, -0.0096, -0.0183, -0.0546,\n",
      "         0.0499,  0.0978,  0.0807, -0.0637,  0.0234,  0.0971, -0.0885,  0.0647,\n",
      "         0.0465,  0.0655,  0.0012, -0.0026,  0.0804, -0.0918,  0.0414,  0.1046],\n",
      "       device='cuda:0') Running Var: tensor([0.5219, 0.6260, 0.2623, 0.1737, 0.6032, 0.3327, 0.4418, 0.4012, 0.2869,\n",
      "        0.5944, 0.2783, 0.8501, 0.2887, 0.1963, 0.2587, 0.6639, 0.3632, 0.4458,\n",
      "        0.2297, 0.4498, 0.7134, 0.6362, 0.4739, 0.3496, 0.3868, 0.3969, 0.3175,\n",
      "        0.7529, 0.3768, 0.3556, 0.1947, 0.2925], device='cuda:0')\n",
      " | Test Loss: 2.094 | Test Acc: 35.010\n",
      "\n",
      "=====> Epoch: 1, Loss: 2.094364333756, Acc: 35.010\n",
      "Running Mean: tensor([-0.0754,  0.0048, -0.0312,  0.0310,  0.0010, -0.0279, -0.0264,  0.1023,\n",
      "        -0.0350,  0.1501, -0.0757, -0.0172, -0.0216, -0.0094, -0.0183, -0.0551,\n",
      "         0.0505,  0.0974,  0.0809, -0.0635,  0.0236,  0.0968, -0.0886,  0.0649,\n",
      "         0.0470,  0.0657,  0.0011, -0.0033,  0.0808, -0.0917,  0.0417,  0.1038],\n",
      "       device='cuda:0') Running Var: tensor([0.5181, 0.6218, 0.2579, 0.1759, 0.5958, 0.3240, 0.4367, 0.3983, 0.2834,\n",
      "        0.5883, 0.2754, 0.8436, 0.2873, 0.1973, 0.2557, 0.6570, 0.3611, 0.4393,\n",
      "        0.2282, 0.4487, 0.7052, 0.6301, 0.4716, 0.3434, 0.3846, 0.3954, 0.3135,\n",
      "        0.7505, 0.3766, 0.3506, 0.1938, 0.2886], device='cuda:0')\n",
      " | Test Loss: 1.949 | Test Acc: 38.270\n",
      "\n",
      "=====> Epoch: 2, Loss: 1.948895356323, Acc: 38.270\n",
      "Running Mean: tensor([-0.0757,  0.0051, -0.0314,  0.0321,  0.0012, -0.0279, -0.0258,  0.1021,\n",
      "        -0.0349,  0.1505, -0.0752, -0.0171, -0.0222, -0.0092, -0.0184, -0.0556,\n",
      "         0.0510,  0.0971,  0.0811, -0.0634,  0.0238,  0.0966, -0.0888,  0.0651,\n",
      "         0.0474,  0.0658,  0.0010, -0.0039,  0.0812, -0.0917,  0.0420,  0.1030],\n",
      "       device='cuda:0') Running Var: tensor([0.5148, 0.6181, 0.2539, 0.1778, 0.5892, 0.3162, 0.4320, 0.3957, 0.2802,\n",
      "        0.5829, 0.2728, 0.8377, 0.2859, 0.1983, 0.2529, 0.6509, 0.3592, 0.4335,\n",
      "        0.2269, 0.4476, 0.6979, 0.6247, 0.4696, 0.3378, 0.3826, 0.3941, 0.3099,\n",
      "        0.7484, 0.3763, 0.3461, 0.1930, 0.2851], device='cuda:0')\n",
      " | Test Loss: 1.828 | Test Acc: 41.200\n",
      "\n",
      "=====> Epoch: 3, Loss: 1.828326033641, Acc: 41.200\n",
      "Running Mean: tensor([-0.0759,  0.0054, -0.0315,  0.0330,  0.0014, -0.0279, -0.0253,  0.1020,\n",
      "        -0.0349,  0.1508, -0.0747, -0.0169, -0.0227, -0.0090, -0.0184, -0.0560,\n",
      "         0.0515,  0.0967,  0.0812, -0.0633,  0.0240,  0.0964, -0.0889,  0.0653,\n",
      "         0.0478,  0.0660,  0.0009, -0.0045,  0.0815, -0.0917,  0.0422,  0.1023],\n",
      "       device='cuda:0') Running Var: tensor([0.5117, 0.6147, 0.2503, 0.1796, 0.5832, 0.3091, 0.4278, 0.3934, 0.2774,\n",
      "        0.5779, 0.2704, 0.8324, 0.2848, 0.1992, 0.2504, 0.6453, 0.3576, 0.4282,\n",
      "        0.2257, 0.4467, 0.6912, 0.6198, 0.4678, 0.3327, 0.3807, 0.3929, 0.3066,\n",
      "        0.7465, 0.3762, 0.3420, 0.1923, 0.2820], device='cuda:0')\n",
      " | Test Loss: 1.730 | Test Acc: 44.000\n",
      "\n",
      "=====> Epoch: 4, Loss: 1.730291713642, Acc: 44.000\n",
      "Running Mean: tensor([-0.0761,  0.0057, -0.0316,  0.0338,  0.0016, -0.0279, -0.0248,  0.1018,\n",
      "        -0.0348,  0.1511, -0.0743, -0.0168, -0.0232, -0.0088, -0.0184, -0.0564,\n",
      "         0.0519,  0.0965,  0.0813, -0.0632,  0.0241,  0.0962, -0.0889,  0.0655,\n",
      "         0.0482,  0.0661,  0.0009, -0.0050,  0.0818, -0.0916,  0.0424,  0.1017],\n",
      "       device='cuda:0') Running Var: tensor([0.5090, 0.6116, 0.2471, 0.1812, 0.5778, 0.3028, 0.4240, 0.3913, 0.2748,\n",
      "        0.5735, 0.2683, 0.8277, 0.2837, 0.1999, 0.2481, 0.6403, 0.3561, 0.4235,\n",
      "        0.2247, 0.4459, 0.6853, 0.6153, 0.4662, 0.3282, 0.3791, 0.3918, 0.3037,\n",
      "        0.7448, 0.3760, 0.3383, 0.1917, 0.2792], device='cuda:0')\n",
      " | Test Loss: 1.652 | Test Acc: 45.990\n",
      "\n",
      "=====> Epoch: 5, Loss: 1.652131661584, Acc: 45.990\n",
      "Running Mean: tensor([-0.0763,  0.0059, -0.0317,  0.0345,  0.0017, -0.0279, -0.0243,  0.1017,\n",
      "        -0.0348,  0.1513, -0.0739, -0.0167, -0.0236, -0.0087, -0.0184, -0.0567,\n",
      "         0.0523,  0.0962,  0.0814, -0.0631,  0.0243,  0.0960, -0.0890,  0.0657,\n",
      "         0.0485,  0.0662,  0.0008, -0.0055,  0.0820, -0.0916,  0.0426,  0.1012],\n",
      "       device='cuda:0') Running Var: tensor([0.5066, 0.6089, 0.2442, 0.1826, 0.5730, 0.2970, 0.4207, 0.3894, 0.2725,\n",
      "        0.5695, 0.2664, 0.8234, 0.2827, 0.2006, 0.2461, 0.6358, 0.3547, 0.4192,\n",
      "        0.2237, 0.4452, 0.6799, 0.6114, 0.4647, 0.3241, 0.3776, 0.3909, 0.3010,\n",
      "        0.7433, 0.3758, 0.3351, 0.1911, 0.2766], device='cuda:0')\n",
      " | Test Loss: 1.591 | Test Acc: 47.650\n",
      "\n",
      "=====> Epoch: 6, Loss: 1.591104785098, Acc: 47.650\n",
      "Running Mean: tensor([-0.0765,  0.0061, -0.0318,  0.0352,  0.0019, -0.0279, -0.0239,  0.1016,\n",
      "        -0.0348,  0.1516, -0.0736, -0.0167, -0.0240, -0.0085, -0.0185, -0.0570,\n",
      "         0.0526,  0.0960,  0.0815, -0.0631,  0.0244,  0.0959, -0.0891,  0.0658,\n",
      "         0.0488,  0.0663,  0.0007, -0.0059,  0.0823, -0.0916,  0.0428,  0.1007],\n",
      "       device='cuda:0') Running Var: tensor([0.5044, 0.6065, 0.2416, 0.1838, 0.5686, 0.2919, 0.4176, 0.3878, 0.2705,\n",
      "        0.5660, 0.2646, 0.8195, 0.2819, 0.2013, 0.2443, 0.6318, 0.3535, 0.4154,\n",
      "        0.2228, 0.4445, 0.6751, 0.6078, 0.4634, 0.3204, 0.3763, 0.3900, 0.2986,\n",
      "        0.7419, 0.3757, 0.3321, 0.1906, 0.2743], device='cuda:0')\n",
      " | Test Loss: 1.545 | Test Acc: 49.070\n",
      "\n",
      "=====> Epoch: 7, Loss: 1.544623183299, Acc: 49.070\n",
      "Running Mean: tensor([-0.0767,  0.0063, -0.0319,  0.0358,  0.0020, -0.0279, -0.0235,  0.1015,\n",
      "        -0.0347,  0.1518, -0.0733, -0.0166, -0.0243, -0.0084, -0.0185, -0.0573,\n",
      "         0.0529,  0.0958,  0.0816, -0.0630,  0.0245,  0.0958, -0.0892,  0.0660,\n",
      "         0.0490,  0.0664,  0.0007, -0.0062,  0.0825, -0.0916,  0.0430,  0.1002],\n",
      "       device='cuda:0') Running Var: tensor([0.5024, 0.6042, 0.2392, 0.1850, 0.5647, 0.2873, 0.4149, 0.3862, 0.2686,\n",
      "        0.5627, 0.2631, 0.8161, 0.2811, 0.2018, 0.2427, 0.6281, 0.3524, 0.4119,\n",
      "        0.2221, 0.4439, 0.6708, 0.6046, 0.4622, 0.3171, 0.3751, 0.3893, 0.2965,\n",
      "        0.7406, 0.3756, 0.3294, 0.1901, 0.2722], device='cuda:0')\n",
      " | Test Loss: 1.510 | Test Acc: 49.930\n",
      "\n",
      "=====> Epoch: 8, Loss: 1.510328647457, Acc: 49.930\n",
      "Running Mean: tensor([-0.0768,  0.0065, -0.0320,  0.0364,  0.0021, -0.0279, -0.0232,  0.1014,\n",
      "        -0.0347,  0.1519, -0.0731, -0.0165, -0.0246, -0.0083, -0.0185, -0.0575,\n",
      "         0.0532,  0.0956,  0.0817, -0.0629,  0.0246,  0.0956, -0.0892,  0.0661,\n",
      "         0.0493,  0.0665,  0.0006, -0.0066,  0.0826, -0.0916,  0.0431,  0.0998],\n",
      "       device='cuda:0') Running Var: tensor([0.5006, 0.6023, 0.2371, 0.1860, 0.5611, 0.2831, 0.4124, 0.3849, 0.2669,\n",
      "        0.5598, 0.2617, 0.8129, 0.2804, 0.2023, 0.2412, 0.6249, 0.3514, 0.4088,\n",
      "        0.2214, 0.4433, 0.6669, 0.6017, 0.4611, 0.3141, 0.3740, 0.3886, 0.2945,\n",
      "        0.7395, 0.3754, 0.3270, 0.1897, 0.2704], device='cuda:0')\n",
      " | Test Loss: 1.486 | Test Acc: 50.780\n",
      "\n",
      "=====> Epoch: 9, Loss: 1.486150482033, Acc: 50.780\n",
      "Running Mean: tensor([-0.0769,  0.0066, -0.0321,  0.0368,  0.0022, -0.0279, -0.0229,  0.1014,\n",
      "        -0.0347,  0.1521, -0.0728, -0.0164, -0.0249, -0.0082, -0.0185, -0.0577,\n",
      "         0.0534,  0.0954,  0.0817, -0.0629,  0.0247,  0.0955, -0.0893,  0.0662,\n",
      "         0.0495,  0.0666,  0.0006, -0.0069,  0.0828, -0.0915,  0.0432,  0.0994],\n",
      "       device='cuda:0') Running Var: tensor([0.4990, 0.6005, 0.2352, 0.1870, 0.5580, 0.2794, 0.4102, 0.3836, 0.2654,\n",
      "        0.5572, 0.2605, 0.8101, 0.2797, 0.2028, 0.2398, 0.6219, 0.3505, 0.4060,\n",
      "        0.2207, 0.4429, 0.6634, 0.5991, 0.4602, 0.3115, 0.3730, 0.3879, 0.2928,\n",
      "        0.7385, 0.3753, 0.3249, 0.1893, 0.2687], device='cuda:0')\n",
      " | Test Loss: 1.470 | Test Acc: 51.470\n",
      "\n",
      "=====> Epoch: 10, Loss: 1.470275300968, Acc: 51.470\n",
      "Running Mean: tensor([-0.0770,  0.0068, -0.0322,  0.0373,  0.0023, -0.0279, -0.0226,  0.1013,\n",
      "        -0.0347,  0.1523, -0.0726, -0.0164, -0.0252, -0.0081, -0.0185, -0.0579,\n",
      "         0.0536,  0.0953,  0.0818, -0.0628,  0.0248,  0.0954, -0.0893,  0.0663,\n",
      "         0.0497,  0.0667,  0.0005, -0.0071,  0.0830, -0.0915,  0.0433,  0.0991],\n",
      "       device='cuda:0') Running Var: tensor([0.4975, 0.5989, 0.2335, 0.1878, 0.5551, 0.2760, 0.4082, 0.3825, 0.2640,\n",
      "        0.5549, 0.2593, 0.8076, 0.2792, 0.2032, 0.2387, 0.6193, 0.3497, 0.4035,\n",
      "        0.2202, 0.4424, 0.6602, 0.5967, 0.4593, 0.3091, 0.3722, 0.3874, 0.2912,\n",
      "        0.7376, 0.3752, 0.3229, 0.1890, 0.2672], device='cuda:0')\n",
      " | Test Loss: 1.461 | Test Acc: 52.020\n",
      "\n",
      "=====> Epoch: 11, Loss: 1.461155707323, Acc: 52.020\n",
      "Running Mean: tensor([-0.0771,  0.0069, -0.0322,  0.0377,  0.0024, -0.0279, -0.0224,  0.1012,\n",
      "        -0.0347,  0.1524, -0.0724, -0.0163, -0.0254, -0.0080, -0.0185, -0.0581,\n",
      "         0.0538,  0.0951,  0.0819, -0.0628,  0.0249,  0.0953, -0.0894,  0.0664,\n",
      "         0.0498,  0.0667,  0.0005, -0.0074,  0.0831, -0.0915,  0.0434,  0.0988],\n",
      "       device='cuda:0') Running Var: tensor([0.4962, 0.5974, 0.2320, 0.1886, 0.5525, 0.2730, 0.4064, 0.3815, 0.2628,\n",
      "        0.5527, 0.2583, 0.8053, 0.2787, 0.2036, 0.2376, 0.6169, 0.3490, 0.4012,\n",
      "        0.2197, 0.4420, 0.6574, 0.5946, 0.4585, 0.3069, 0.3714, 0.3868, 0.2898,\n",
      "        0.7368, 0.3752, 0.3212, 0.1887, 0.2659], device='cuda:0')\n",
      " | Test Loss: 1.457 | Test Acc: 52.110\n",
      "\n",
      "=====> Epoch: 12, Loss: 1.457468701314, Acc: 52.110\n",
      "Running Mean: tensor([-0.0772,  0.0070, -0.0323,  0.0380,  0.0024, -0.0279, -0.0222,  0.1012,\n",
      "        -0.0346,  0.1525, -0.0722, -0.0163, -0.0256, -0.0079, -0.0185, -0.0583,\n",
      "         0.0540,  0.0950,  0.0819, -0.0627,  0.0250,  0.0953, -0.0894,  0.0665,\n",
      "         0.0500,  0.0668,  0.0005, -0.0076,  0.0832, -0.0915,  0.0435,  0.0985],\n",
      "       device='cuda:0') Running Var: tensor([0.4950, 0.5961, 0.2306, 0.1892, 0.5502, 0.2702, 0.4047, 0.3806, 0.2617,\n",
      "        0.5508, 0.2574, 0.8033, 0.2782, 0.2039, 0.2366, 0.6147, 0.3484, 0.3992,\n",
      "        0.2192, 0.4417, 0.6548, 0.5927, 0.4578, 0.3049, 0.3707, 0.3864, 0.2886,\n",
      "        0.7360, 0.3751, 0.3196, 0.1884, 0.2646], device='cuda:0')\n",
      " | Test Loss: 1.458 | Test Acc: 52.260\n",
      "\n",
      "=====> Epoch: 13, Loss: 1.458077337168, Acc: 52.260\n",
      "Running Mean: tensor([-0.0773,  0.0071, -0.0323,  0.0384,  0.0025, -0.0279, -0.0220,  0.1011,\n",
      "        -0.0346,  0.1526, -0.0721, -0.0162, -0.0258, -0.0079, -0.0186, -0.0584,\n",
      "         0.0542,  0.0949,  0.0820, -0.0627,  0.0250,  0.0952, -0.0895,  0.0666,\n",
      "         0.0501,  0.0669,  0.0004, -0.0078,  0.0833, -0.0915,  0.0436,  0.0983],\n",
      "       device='cuda:0') Running Var: tensor([0.4940, 0.5949, 0.2293, 0.1898, 0.5481, 0.2678, 0.4033, 0.3798, 0.2607,\n",
      "        0.5491, 0.2566, 0.8014, 0.2778, 0.2042, 0.2357, 0.6128, 0.3478, 0.3973,\n",
      "        0.2188, 0.4414, 0.6525, 0.5910, 0.4572, 0.3032, 0.3700, 0.3860, 0.2874,\n",
      "        0.7354, 0.3750, 0.3182, 0.1882, 0.2635], device='cuda:0')\n",
      " | Test Loss: 1.462 | Test Acc: 52.370\n",
      "\n",
      "=====> Epoch: 14, Loss: 1.462002888510, Acc: 52.370\n",
      "Running Mean: tensor([-0.0774,  0.0072, -0.0324,  0.0386,  0.0026, -0.0279, -0.0218,  0.1011,\n",
      "        -0.0346,  0.1527, -0.0719, -0.0162, -0.0260, -0.0078, -0.0186, -0.0585,\n",
      "         0.0543,  0.0948,  0.0820, -0.0627,  0.0251,  0.0951, -0.0895,  0.0666,\n",
      "         0.0503,  0.0669,  0.0004, -0.0079,  0.0834, -0.0915,  0.0437,  0.0981],\n",
      "       device='cuda:0') Running Var: tensor([0.4930, 0.5939, 0.2282, 0.1904, 0.5463, 0.2655, 0.4020, 0.3791, 0.2598,\n",
      "        0.5476, 0.2558, 0.7998, 0.2774, 0.2045, 0.2350, 0.6110, 0.3472, 0.3957,\n",
      "        0.2184, 0.4411, 0.6504, 0.5895, 0.4566, 0.3016, 0.3695, 0.3856, 0.2864,\n",
      "        0.7348, 0.3750, 0.3169, 0.1880, 0.2626], device='cuda:0')\n",
      " | Test Loss: 1.468 | Test Acc: 52.450\n",
      "\n",
      "=====> Epoch: 15, Loss: 1.468414027480, Acc: 52.450\n",
      "Running Mean: tensor([-0.0775,  0.0073, -0.0324,  0.0389,  0.0026, -0.0279, -0.0217,  0.1010,\n",
      "        -0.0346,  0.1528, -0.0718, -0.0162, -0.0261, -0.0078, -0.0186, -0.0586,\n",
      "         0.0544,  0.0947,  0.0820, -0.0626,  0.0252,  0.0951, -0.0895,  0.0667,\n",
      "         0.0504,  0.0669,  0.0004, -0.0081,  0.0835, -0.0915,  0.0437,  0.0979],\n",
      "       device='cuda:0') Running Var: tensor([0.4922, 0.5929, 0.2272, 0.1909, 0.5446, 0.2636, 0.4008, 0.3785, 0.2590,\n",
      "        0.5462, 0.2552, 0.7983, 0.2771, 0.2047, 0.2342, 0.6095, 0.3468, 0.3942,\n",
      "        0.2181, 0.4408, 0.6486, 0.5881, 0.4561, 0.3002, 0.3690, 0.3853, 0.2855,\n",
      "        0.7342, 0.3749, 0.3158, 0.1878, 0.2617], device='cuda:0')\n",
      " | Test Loss: 1.477 | Test Acc: 52.410\n",
      "\n",
      "=====> Epoch: 16, Loss: 1.476650438731, Acc: 52.410\n",
      "Running Mean: tensor([-0.0775,  0.0074, -0.0324,  0.0391,  0.0027, -0.0279, -0.0215,  0.1010,\n",
      "        -0.0346,  0.1529, -0.0717, -0.0161, -0.0262, -0.0077, -0.0186, -0.0588,\n",
      "         0.0545,  0.0946,  0.0821, -0.0626,  0.0252,  0.0950, -0.0895,  0.0667,\n",
      "         0.0505,  0.0670,  0.0004, -0.0082,  0.0836, -0.0915,  0.0438,  0.0977],\n",
      "       device='cuda:0') Running Var: tensor([0.4914, 0.5921, 0.2263, 0.1913, 0.5430, 0.2618, 0.3997, 0.3779, 0.2583,\n",
      "        0.5449, 0.2546, 0.7969, 0.2768, 0.2050, 0.2336, 0.6081, 0.3463, 0.3929,\n",
      "        0.2178, 0.4406, 0.6469, 0.5868, 0.4557, 0.2989, 0.3685, 0.3850, 0.2846,\n",
      "        0.7338, 0.3748, 0.3147, 0.1876, 0.2609], device='cuda:0')\n",
      " | Test Loss: 1.486 | Test Acc: 52.260\n",
      "\n",
      "=====> Epoch: 17, Loss: 1.486190474486, Acc: 52.260\n",
      "Running Mean: tensor([-0.0776,  0.0074, -0.0325,  0.0393,  0.0027, -0.0278, -0.0214,  0.1010,\n",
      "        -0.0346,  0.1530, -0.0716, -0.0161, -0.0264, -0.0077, -0.0186, -0.0588,\n",
      "         0.0546,  0.0946,  0.0821, -0.0626,  0.0252,  0.0950, -0.0896,  0.0668,\n",
      "         0.0506,  0.0670,  0.0003, -0.0084,  0.0837, -0.0915,  0.0439,  0.0976],\n",
      "       device='cuda:0') Running Var: tensor([0.4907, 0.5913, 0.2254, 0.1917, 0.5417, 0.2601, 0.3988, 0.3773, 0.2577,\n",
      "        0.5438, 0.2540, 0.7957, 0.2765, 0.2052, 0.2330, 0.6068, 0.3460, 0.3917,\n",
      "        0.2175, 0.4404, 0.6454, 0.5857, 0.4553, 0.2977, 0.3681, 0.3847, 0.2839,\n",
      "        0.7333, 0.3748, 0.3138, 0.1874, 0.2601], device='cuda:0')\n",
      " | Test Loss: 1.497 | Test Acc: 52.130\n",
      "\n",
      "=====> Epoch: 18, Loss: 1.496599063089, Acc: 52.130\n",
      "Running Mean: tensor([-0.0776,  0.0075, -0.0325,  0.0395,  0.0027, -0.0278, -0.0213,  0.1009,\n",
      "        -0.0346,  0.1531, -0.0715, -0.0161, -0.0265, -0.0076, -0.0186, -0.0589,\n",
      "         0.0547,  0.0945,  0.0821, -0.0625,  0.0253,  0.0949, -0.0896,  0.0668,\n",
      "         0.0506,  0.0670,  0.0003, -0.0085,  0.0837, -0.0915,  0.0439,  0.0974],\n",
      "       device='cuda:0') Running Var: tensor([0.4901, 0.5906, 0.2247, 0.1921, 0.5404, 0.2587, 0.3979, 0.3769, 0.2571,\n",
      "        0.5428, 0.2535, 0.7946, 0.2763, 0.2053, 0.2325, 0.6057, 0.3456, 0.3906,\n",
      "        0.2173, 0.4402, 0.6440, 0.5847, 0.4549, 0.2967, 0.3677, 0.3845, 0.2832,\n",
      "        0.7329, 0.3748, 0.3130, 0.1873, 0.2595], device='cuda:0')\n",
      " | Test Loss: 1.507 | Test Acc: 52.030\n",
      "\n",
      "=====> Epoch: 19, Loss: 1.507497651668, Acc: 52.030\n",
      "Running Mean: tensor([-0.0777,  0.0076, -0.0325,  0.0397,  0.0028, -0.0278, -0.0212,  0.1009,\n",
      "        -0.0346,  0.1531, -0.0714, -0.0161, -0.0266, -0.0076, -0.0186, -0.0590,\n",
      "         0.0548,  0.0944,  0.0822, -0.0625,  0.0253,  0.0949, -0.0896,  0.0669,\n",
      "         0.0507,  0.0671,  0.0003, -0.0086,  0.0838, -0.0914,  0.0440,  0.0973],\n",
      "       device='cuda:0') Running Var: tensor([0.4895, 0.5900, 0.2240, 0.1924, 0.5393, 0.2574, 0.3971, 0.3764, 0.2566,\n",
      "        0.5419, 0.2531, 0.7937, 0.2760, 0.2055, 0.2321, 0.6046, 0.3453, 0.3896,\n",
      "        0.2170, 0.4400, 0.6428, 0.5838, 0.4545, 0.2958, 0.3674, 0.3842, 0.2826,\n",
      "        0.7326, 0.3747, 0.3122, 0.1871, 0.2589], device='cuda:0')\n",
      " | Test Loss: 1.519 | Test Acc: 51.900\n",
      "\n",
      "=====> Epoch: 20, Loss: 1.518596881553, Acc: 51.900\n",
      "Running Mean: tensor([-0.0777,  0.0076, -0.0325,  0.0399,  0.0028, -0.0278, -0.0211,  0.1009,\n",
      "        -0.0346,  0.1532, -0.0713, -0.0160, -0.0267, -0.0076, -0.0186, -0.0591,\n",
      "         0.0549,  0.0944,  0.0822, -0.0625,  0.0253,  0.0948, -0.0896,  0.0669,\n",
      "         0.0508,  0.0671,  0.0003, -0.0087,  0.0838, -0.0914,  0.0440,  0.0972],\n",
      "       device='cuda:0') Running Var: tensor([0.4890, 0.5894, 0.2234, 0.1927, 0.5383, 0.2562, 0.3964, 0.3760, 0.2561,\n",
      "        0.5411, 0.2527, 0.7928, 0.2758, 0.2056, 0.2316, 0.6037, 0.3450, 0.3887,\n",
      "        0.2168, 0.4399, 0.6417, 0.5830, 0.4542, 0.2949, 0.3671, 0.3840, 0.2821,\n",
      "        0.7323, 0.3747, 0.3116, 0.1870, 0.2584], device='cuda:0')\n",
      " | Test Loss: 1.530 | Test Acc: 51.820\n",
      "\n",
      "=====> Epoch: 21, Loss: 1.529674960088, Acc: 51.820\n",
      "Running Mean: tensor([-0.0778,  0.0076, -0.0326,  0.0400,  0.0028, -0.0278, -0.0210,  0.1009,\n",
      "        -0.0346,  0.1532, -0.0713, -0.0160, -0.0267, -0.0076, -0.0186, -0.0591,\n",
      "         0.0550,  0.0943,  0.0822, -0.0625,  0.0254,  0.0948, -0.0896,  0.0669,\n",
      "         0.0508,  0.0671,  0.0003, -0.0088,  0.0839, -0.0914,  0.0440,  0.0971],\n",
      "       device='cuda:0') Running Var: tensor([0.4886, 0.5889, 0.2229, 0.1930, 0.5374, 0.2552, 0.3958, 0.3757, 0.2557,\n",
      "        0.5403, 0.2524, 0.7920, 0.2757, 0.2058, 0.2313, 0.6029, 0.3448, 0.3879,\n",
      "        0.2167, 0.4397, 0.6407, 0.5822, 0.4540, 0.2942, 0.3668, 0.3839, 0.2816,\n",
      "        0.7320, 0.3747, 0.3109, 0.1869, 0.2579], device='cuda:0')\n",
      " | Test Loss: 1.541 | Test Acc: 51.620\n",
      "\n",
      "=====> Epoch: 22, Loss: 1.540570671045, Acc: 51.620\n",
      "Running Mean: tensor([-0.0778,  0.0077, -0.0326,  0.0401,  0.0029, -0.0278, -0.0209,  0.1008,\n",
      "        -0.0345,  0.1533, -0.0712, -0.0160, -0.0268, -0.0075, -0.0186, -0.0592,\n",
      "         0.0550,  0.0943,  0.0822, -0.0625,  0.0254,  0.0948, -0.0896,  0.0669,\n",
      "         0.0509,  0.0671,  0.0003, -0.0088,  0.0839, -0.0914,  0.0441,  0.0970],\n",
      "       device='cuda:0') Running Var: tensor([0.4882, 0.5884, 0.2224, 0.1932, 0.5366, 0.2542, 0.3952, 0.3754, 0.2553,\n",
      "        0.5397, 0.2520, 0.7913, 0.2755, 0.2059, 0.2309, 0.6021, 0.3446, 0.3872,\n",
      "        0.2165, 0.4396, 0.6398, 0.5816, 0.4537, 0.2935, 0.3665, 0.3837, 0.2811,\n",
      "        0.7317, 0.3746, 0.3104, 0.1868, 0.2575], device='cuda:0')\n",
      " | Test Loss: 1.551 | Test Acc: 51.500\n",
      "\n",
      "=====> Epoch: 23, Loss: 1.551136169253, Acc: 51.500\n",
      "Running Mean: tensor([-0.0778,  0.0077, -0.0326,  0.0402,  0.0029, -0.0278, -0.0209,  0.1008,\n",
      "        -0.0345,  0.1533, -0.0712, -0.0160, -0.0269, -0.0075, -0.0186, -0.0592,\n",
      "         0.0551,  0.0943,  0.0822, -0.0625,  0.0254,  0.0948, -0.0897,  0.0670,\n",
      "         0.0509,  0.0672,  0.0002, -0.0089,  0.0840, -0.0914,  0.0441,  0.0969],\n",
      "       device='cuda:0') Running Var: tensor([0.4878, 0.5880, 0.2220, 0.1934, 0.5359, 0.2533, 0.3947, 0.3751, 0.2549,\n",
      "        0.5391, 0.2518, 0.7906, 0.2754, 0.2060, 0.2306, 0.6014, 0.3444, 0.3866,\n",
      "        0.2164, 0.4395, 0.6390, 0.5810, 0.4535, 0.2929, 0.3663, 0.3836, 0.2807,\n",
      "        0.7315, 0.3746, 0.3099, 0.1867, 0.2571], device='cuda:0')\n",
      " | Test Loss: 1.561 | Test Acc: 51.390\n",
      "\n",
      "=====> Epoch: 24, Loss: 1.561282434041, Acc: 51.390\n",
      "Running Mean: tensor([-0.0778,  0.0078, -0.0326,  0.0403,  0.0029, -0.0278, -0.0208,  0.1008,\n",
      "        -0.0345,  0.1533, -0.0711, -0.0160, -0.0269, -0.0075, -0.0186, -0.0593,\n",
      "         0.0551,  0.0942,  0.0822, -0.0625,  0.0254,  0.0947, -0.0897,  0.0670,\n",
      "         0.0510,  0.0672,  0.0002, -0.0090,  0.0840, -0.0914,  0.0441,  0.0968],\n",
      "       device='cuda:0') Running Var: tensor([0.4875, 0.5877, 0.2216, 0.1936, 0.5353, 0.2526, 0.3943, 0.3748, 0.2546,\n",
      "        0.5385, 0.2515, 0.7900, 0.2752, 0.2061, 0.2304, 0.6008, 0.3442, 0.3860,\n",
      "        0.2162, 0.4394, 0.6383, 0.5804, 0.4533, 0.2923, 0.3661, 0.3834, 0.2804,\n",
      "        0.7313, 0.3746, 0.3095, 0.1867, 0.2568], device='cuda:0')\n",
      " | Test Loss: 1.571 | Test Acc: 51.250\n",
      "\n",
      "=====> Epoch: 25, Loss: 1.570942284186, Acc: 51.250\n",
      "Running Mean: tensor([-0.0779,  0.0078, -0.0326,  0.0404,  0.0029, -0.0278, -0.0207,  0.1008,\n",
      "        -0.0345,  0.1534, -0.0711, -0.0160, -0.0270, -0.0075, -0.0186, -0.0593,\n",
      "         0.0552,  0.0942,  0.0823, -0.0624,  0.0255,  0.0947, -0.0897,  0.0670,\n",
      "         0.0510,  0.0672,  0.0002, -0.0090,  0.0840, -0.0914,  0.0441,  0.0967],\n",
      "       device='cuda:0') Running Var: tensor([0.4872, 0.5873, 0.2212, 0.1938, 0.5347, 0.2519, 0.3938, 0.3746, 0.2543,\n",
      "        0.5381, 0.2513, 0.7895, 0.2751, 0.2062, 0.2301, 0.6003, 0.3440, 0.3855,\n",
      "        0.2161, 0.4393, 0.6376, 0.5799, 0.4531, 0.2918, 0.3659, 0.3833, 0.2801,\n",
      "        0.7311, 0.3746, 0.3091, 0.1866, 0.2565], device='cuda:0')\n",
      " | Test Loss: 1.580 | Test Acc: 51.150\n",
      "\n",
      "=====> Epoch: 26, Loss: 1.580080009714, Acc: 51.150\n",
      "Running Mean: tensor([-0.0779,  0.0078, -0.0326,  0.0405,  0.0029, -0.0278, -0.0207,  0.1008,\n",
      "        -0.0345,  0.1534, -0.0710, -0.0160, -0.0270, -0.0074, -0.0186, -0.0594,\n",
      "         0.0552,  0.0942,  0.0823, -0.0624,  0.0255,  0.0947, -0.0897,  0.0670,\n",
      "         0.0510,  0.0672,  0.0002, -0.0091,  0.0841, -0.0914,  0.0442,  0.0967],\n",
      "       device='cuda:0') Running Var: tensor([0.4869, 0.5870, 0.2209, 0.1939, 0.5341, 0.2513, 0.3935, 0.3744, 0.2541,\n",
      "        0.5376, 0.2511, 0.7891, 0.2750, 0.2063, 0.2299, 0.5998, 0.3439, 0.3850,\n",
      "        0.2160, 0.4392, 0.6370, 0.5795, 0.4530, 0.2914, 0.3658, 0.3832, 0.2798,\n",
      "        0.7309, 0.3746, 0.3087, 0.1865, 0.2562], device='cuda:0')\n",
      " | Test Loss: 1.589 | Test Acc: 51.130\n",
      "\n",
      "=====> Epoch: 27, Loss: 1.588671521295, Acc: 51.130\n",
      "Running Mean: tensor([-0.0779,  0.0078, -0.0326,  0.0406,  0.0030, -0.0278, -0.0206,  0.1008,\n",
      "        -0.0345,  0.1534, -0.0710, -0.0159, -0.0271, -0.0074, -0.0186, -0.0594,\n",
      "         0.0553,  0.0941,  0.0823, -0.0624,  0.0255,  0.0947, -0.0897,  0.0671,\n",
      "         0.0511,  0.0672,  0.0002, -0.0091,  0.0841, -0.0914,  0.0442,  0.0966],\n",
      "       device='cuda:0') Running Var: tensor([0.4866, 0.5868, 0.2206, 0.1941, 0.5337, 0.2507, 0.3931, 0.3742, 0.2539,\n",
      "        0.5372, 0.2509, 0.7886, 0.2749, 0.2063, 0.2297, 0.5994, 0.3437, 0.3846,\n",
      "        0.2159, 0.4391, 0.6365, 0.5791, 0.4528, 0.2910, 0.3656, 0.3831, 0.2795,\n",
      "        0.7308, 0.3745, 0.3084, 0.1865, 0.2559], device='cuda:0')\n",
      " | Test Loss: 1.597 | Test Acc: 50.960\n",
      "\n",
      "=====> Epoch: 28, Loss: 1.596703536903, Acc: 50.960\n",
      "Running Mean: tensor([-0.0779,  0.0079, -0.0327,  0.0406,  0.0030, -0.0278, -0.0206,  0.1008,\n",
      "        -0.0345,  0.1534, -0.0710, -0.0159, -0.0271, -0.0074, -0.0186, -0.0594,\n",
      "         0.0553,  0.0941,  0.0823, -0.0624,  0.0255,  0.0947, -0.0897,  0.0671,\n",
      "         0.0511,  0.0672,  0.0002, -0.0092,  0.0841, -0.0914,  0.0442,  0.0966],\n",
      "       device='cuda:0') Running Var: tensor([0.4864, 0.5865, 0.2204, 0.1942, 0.5332, 0.2502, 0.3928, 0.3741, 0.2537,\n",
      "        0.5369, 0.2507, 0.7883, 0.2748, 0.2064, 0.2295, 0.5990, 0.3436, 0.3842,\n",
      "        0.2158, 0.4391, 0.6360, 0.5788, 0.4527, 0.2906, 0.3655, 0.3830, 0.2793,\n",
      "        0.7306, 0.3745, 0.3081, 0.1864, 0.2557], device='cuda:0')\n",
      " | Test Loss: 1.604 | Test Acc: 50.860\n",
      "\n",
      "=====> Epoch: 29, Loss: 1.604180544238, Acc: 50.860\n",
      "Running Mean: tensor([-0.0779,  0.0079, -0.0327,  0.0407,  0.0030, -0.0278, -0.0206,  0.1007,\n",
      "        -0.0345,  0.1535, -0.0709, -0.0159, -0.0272, -0.0074, -0.0186, -0.0594,\n",
      "         0.0553,  0.0941,  0.0823, -0.0624,  0.0255,  0.0946, -0.0897,  0.0671,\n",
      "         0.0511,  0.0672,  0.0002, -0.0092,  0.0841, -0.0914,  0.0442,  0.0965],\n",
      "       device='cuda:0') Running Var: tensor([0.4862, 0.5863, 0.2201, 0.1943, 0.5328, 0.2497, 0.3926, 0.3739, 0.2535,\n",
      "        0.5366, 0.2505, 0.7879, 0.2747, 0.2064, 0.2294, 0.5986, 0.3435, 0.3839,\n",
      "        0.2158, 0.4390, 0.6356, 0.5785, 0.4526, 0.2903, 0.3654, 0.3830, 0.2791,\n",
      "        0.7305, 0.3745, 0.3078, 0.1864, 0.2555], device='cuda:0')\n",
      " | Test Loss: 1.611 | Test Acc: 50.830\n",
      "\n",
      "=====> Epoch: 30, Loss: 1.611113337022, Acc: 50.830\n",
      "Running Mean: tensor([-0.0780,  0.0079, -0.0327,  0.0408,  0.0030, -0.0278, -0.0205,  0.1007,\n",
      "        -0.0345,  0.1535, -0.0709, -0.0159, -0.0272, -0.0074, -0.0186, -0.0595,\n",
      "         0.0553,  0.0941,  0.0823, -0.0624,  0.0255,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0672,  0.0002, -0.0092,  0.0841, -0.0914,  0.0442,  0.0965],\n",
      "       device='cuda:0') Running Var: tensor([0.4861, 0.5861, 0.2199, 0.1944, 0.5325, 0.2493, 0.3923, 0.3738, 0.2533,\n",
      "        0.5363, 0.2504, 0.7876, 0.2747, 0.2065, 0.2292, 0.5983, 0.3434, 0.3836,\n",
      "        0.2157, 0.4390, 0.6352, 0.5782, 0.4525, 0.2900, 0.3653, 0.3829, 0.2789,\n",
      "        0.7304, 0.3745, 0.3076, 0.1863, 0.2553], device='cuda:0')\n",
      " | Test Loss: 1.618 | Test Acc: 50.750\n",
      "\n",
      "=====> Epoch: 31, Loss: 1.617522638055, Acc: 50.750\n",
      "Running Mean: tensor([-0.0780,  0.0079, -0.0327,  0.0408,  0.0030, -0.0278, -0.0205,  0.1007,\n",
      "        -0.0345,  0.1535, -0.0709, -0.0159, -0.0272, -0.0074, -0.0186, -0.0595,\n",
      "         0.0554,  0.0941,  0.0823, -0.0624,  0.0255,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0673,  0.0002, -0.0092,  0.0842, -0.0914,  0.0442,  0.0965],\n",
      "       device='cuda:0') Running Var: tensor([0.4859, 0.5859, 0.2197, 0.1945, 0.5322, 0.2489, 0.3921, 0.3737, 0.2532,\n",
      "        0.5360, 0.2503, 0.7873, 0.2746, 0.2065, 0.2291, 0.5980, 0.3433, 0.3833,\n",
      "        0.2156, 0.4389, 0.6349, 0.5779, 0.4524, 0.2897, 0.3652, 0.3828, 0.2787,\n",
      "        0.7303, 0.3745, 0.3074, 0.1863, 0.2551], device='cuda:0')\n",
      " | Test Loss: 1.623 | Test Acc: 50.700\n",
      "\n",
      "=====> Epoch: 32, Loss: 1.623431362683, Acc: 50.700\n",
      "Running Mean: tensor([-0.0780,  0.0079, -0.0327,  0.0409,  0.0030, -0.0278, -0.0205,  0.1007,\n",
      "        -0.0345,  0.1535, -0.0709, -0.0159, -0.0272, -0.0074, -0.0186, -0.0595,\n",
      "         0.0554,  0.0940,  0.0823, -0.0624,  0.0255,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0673,  0.0002, -0.0093,  0.0842, -0.0914,  0.0442,  0.0964],\n",
      "       device='cuda:0') Running Var: tensor([0.4858, 0.5858, 0.2196, 0.1946, 0.5319, 0.2486, 0.3919, 0.3735, 0.2530,\n",
      "        0.5358, 0.2502, 0.7871, 0.2746, 0.2066, 0.2290, 0.5977, 0.3432, 0.3830,\n",
      "        0.2156, 0.4389, 0.6346, 0.5777, 0.4523, 0.2895, 0.3651, 0.3828, 0.2785,\n",
      "        0.7302, 0.3745, 0.3072, 0.1863, 0.2550], device='cuda:0')\n",
      " | Test Loss: 1.629 | Test Acc: 50.650\n",
      "\n",
      "=====> Epoch: 33, Loss: 1.628862657124, Acc: 50.650\n",
      "Running Mean: tensor([-0.0780,  0.0079, -0.0327,  0.0409,  0.0030, -0.0278, -0.0205,  0.1007,\n",
      "        -0.0345,  0.1535, -0.0708, -0.0159, -0.0273, -0.0074, -0.0186, -0.0595,\n",
      "         0.0554,  0.0940,  0.0823, -0.0624,  0.0255,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0673,  0.0002, -0.0093,  0.0842, -0.0914,  0.0443,  0.0964],\n",
      "       device='cuda:0') Running Var: tensor([0.4856, 0.5856, 0.2194, 0.1947, 0.5316, 0.2483, 0.3917, 0.3734, 0.2529,\n",
      "        0.5356, 0.2501, 0.7869, 0.2745, 0.2066, 0.2289, 0.5975, 0.3432, 0.3828,\n",
      "        0.2155, 0.4388, 0.6343, 0.5775, 0.4522, 0.2893, 0.3650, 0.3827, 0.2784,\n",
      "        0.7301, 0.3745, 0.3070, 0.1862, 0.2549], device='cuda:0')\n",
      " | Test Loss: 1.634 | Test Acc: 50.670\n",
      "\n",
      "=====> Epoch: 34, Loss: 1.633844618556, Acc: 50.670\n",
      "Running Mean: tensor([-0.0780,  0.0079, -0.0327,  0.0409,  0.0030, -0.0278, -0.0204,  0.1007,\n",
      "        -0.0345,  0.1535, -0.0708, -0.0159, -0.0273, -0.0074, -0.0186, -0.0595,\n",
      "         0.0554,  0.0940,  0.0823, -0.0624,  0.0256,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0673,  0.0002, -0.0093,  0.0842, -0.0914,  0.0443,  0.0964],\n",
      "       device='cuda:0') Running Var: tensor([0.4855, 0.5855, 0.2193, 0.1947, 0.5314, 0.2480, 0.3916, 0.3734, 0.2528,\n",
      "        0.5354, 0.2500, 0.7867, 0.2745, 0.2066, 0.2288, 0.5973, 0.3431, 0.3826,\n",
      "        0.2155, 0.4388, 0.6340, 0.5773, 0.4522, 0.2891, 0.3649, 0.3827, 0.2783,\n",
      "        0.7301, 0.3745, 0.3069, 0.1862, 0.2547], device='cuda:0')\n",
      " | Test Loss: 1.638 | Test Acc: 50.620\n",
      "\n",
      "=====> Epoch: 35, Loss: 1.638404026816, Acc: 50.620\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0410,  0.0030, -0.0278, -0.0204,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0708, -0.0159, -0.0273, -0.0074, -0.0186, -0.0596,\n",
      "         0.0554,  0.0940,  0.0823, -0.0624,  0.0256,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0673,  0.0002, -0.0093,  0.0842, -0.0914,  0.0443,  0.0964],\n",
      "       device='cuda:0') Running Var: tensor([0.4854, 0.5854, 0.2192, 0.1948, 0.5312, 0.2478, 0.3914, 0.3733, 0.2527,\n",
      "        0.5352, 0.2499, 0.7865, 0.2744, 0.2067, 0.2287, 0.5971, 0.3430, 0.3824,\n",
      "        0.2154, 0.4388, 0.6338, 0.5771, 0.4521, 0.2889, 0.3649, 0.3826, 0.2782,\n",
      "        0.7300, 0.3745, 0.3067, 0.1862, 0.2546], device='cuda:0')\n",
      " | Test Loss: 1.643 | Test Acc: 50.520\n",
      "\n",
      "=====> Epoch: 36, Loss: 1.642570347726, Acc: 50.520\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0410,  0.0030, -0.0278, -0.0204,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0708, -0.0159, -0.0273, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0823, -0.0624,  0.0256,  0.0946, -0.0897,  0.0671,\n",
      "         0.0512,  0.0673,  0.0002, -0.0094,  0.0842, -0.0914,  0.0443,  0.0963],\n",
      "       device='cuda:0') Running Var: tensor([0.4853, 0.5853, 0.2191, 0.1948, 0.5310, 0.2476, 0.3913, 0.3732, 0.2526,\n",
      "        0.5351, 0.2498, 0.7863, 0.2744, 0.2067, 0.2286, 0.5969, 0.3430, 0.3823,\n",
      "        0.2154, 0.4387, 0.6336, 0.5770, 0.4520, 0.2888, 0.3648, 0.3826, 0.2781,\n",
      "        0.7299, 0.3745, 0.3066, 0.1862, 0.2545], device='cuda:0')\n",
      " | Test Loss: 1.646 | Test Acc: 50.520\n",
      "\n",
      "=====> Epoch: 37, Loss: 1.646370080453, Acc: 50.520\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0410,  0.0031, -0.0278, -0.0204,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0708, -0.0159, -0.0273, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0823, -0.0624,  0.0256,  0.0946, -0.0897,  0.0671,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0842, -0.0914,  0.0443,  0.0963],\n",
      "       device='cuda:0') Running Var: tensor([0.4852, 0.5852, 0.2190, 0.1949, 0.5309, 0.2474, 0.3912, 0.3731, 0.2525,\n",
      "        0.5349, 0.2498, 0.7862, 0.2744, 0.2067, 0.2285, 0.5968, 0.3429, 0.3821,\n",
      "        0.2154, 0.4387, 0.6334, 0.5768, 0.4520, 0.2886, 0.3648, 0.3826, 0.2780,\n",
      "        0.7299, 0.3745, 0.3065, 0.1861, 0.2545], device='cuda:0')\n",
      " | Test Loss: 1.650 | Test Acc: 50.400\n",
      "\n",
      "=====> Epoch: 38, Loss: 1.649831385552, Acc: 50.400\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0410,  0.0031, -0.0278, -0.0204,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0708, -0.0159, -0.0273, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0823, -0.0624,  0.0256,  0.0946, -0.0897,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0842, -0.0914,  0.0443,  0.0963],\n",
      "       device='cuda:0') Running Var: tensor([0.4852, 0.5851, 0.2189, 0.1949, 0.5307, 0.2472, 0.3911, 0.3731, 0.2525,\n",
      "        0.5348, 0.2497, 0.7860, 0.2743, 0.2067, 0.2285, 0.5966, 0.3429, 0.3820,\n",
      "        0.2153, 0.4387, 0.6333, 0.5767, 0.4519, 0.2885, 0.3647, 0.3825, 0.2779,\n",
      "        0.7298, 0.3744, 0.3064, 0.1861, 0.2544], device='cuda:0')\n",
      " | Test Loss: 1.653 | Test Acc: 50.370\n",
      "\n",
      "=====> Epoch: 39, Loss: 1.652980612803, Acc: 50.370\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0204,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0708, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0823, -0.0624,  0.0256,  0.0946, -0.0897,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0842, -0.0914,  0.0443,  0.0963],\n",
      "       device='cuda:0') Running Var: tensor([0.4851, 0.5850, 0.2188, 0.1950, 0.5306, 0.2471, 0.3910, 0.3730, 0.2524,\n",
      "        0.5347, 0.2497, 0.7859, 0.2743, 0.2068, 0.2284, 0.5965, 0.3429, 0.3819,\n",
      "        0.2153, 0.4387, 0.6331, 0.5766, 0.4519, 0.2884, 0.3647, 0.3825, 0.2778,\n",
      "        0.7298, 0.3744, 0.3063, 0.1861, 0.2543], device='cuda:0')\n",
      " | Test Loss: 1.656 | Test Acc: 50.290\n",
      "\n",
      "=====> Epoch: 40, Loss: 1.655842470217, Acc: 50.290\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0824, -0.0624,  0.0256,  0.0946, -0.0897,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0843, -0.0914,  0.0443,  0.0963],\n",
      "       device='cuda:0') Running Var: tensor([0.4850, 0.5850, 0.2187, 0.1950, 0.5305, 0.2469, 0.3909, 0.3730, 0.2523,\n",
      "        0.5346, 0.2496, 0.7858, 0.2743, 0.2068, 0.2284, 0.5964, 0.3428, 0.3818,\n",
      "        0.2153, 0.4386, 0.6330, 0.5765, 0.4519, 0.2883, 0.3646, 0.3825, 0.2777,\n",
      "        0.7298, 0.3744, 0.3062, 0.1861, 0.2542], device='cuda:0')\n",
      " | Test Loss: 1.658 | Test Acc: 50.280\n",
      "\n",
      "=====> Epoch: 41, Loss: 1.658440586887, Acc: 50.280\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0824, -0.0624,  0.0256,  0.0946, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0843, -0.0914,  0.0443,  0.0963],\n",
      "       device='cuda:0') Running Var: tensor([0.4850, 0.5849, 0.2186, 0.1950, 0.5303, 0.2468, 0.3908, 0.3729, 0.2523,\n",
      "        0.5345, 0.2496, 0.7857, 0.2743, 0.2068, 0.2283, 0.5963, 0.3428, 0.3817,\n",
      "        0.2153, 0.4386, 0.6329, 0.5764, 0.4518, 0.2882, 0.3646, 0.3825, 0.2777,\n",
      "        0.7297, 0.3744, 0.3061, 0.1861, 0.2542], device='cuda:0')\n",
      " | Test Loss: 1.661 | Test Acc: 50.250\n",
      "\n",
      "=====> Epoch: 42, Loss: 1.660797301727, Acc: 50.250\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0824, -0.0624,  0.0256,  0.0946, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4849, 0.5848, 0.2186, 0.1951, 0.5303, 0.2467, 0.3908, 0.3729, 0.2523,\n",
      "        0.5344, 0.2495, 0.7856, 0.2742, 0.2068, 0.2283, 0.5962, 0.3428, 0.3816,\n",
      "        0.2152, 0.4386, 0.6328, 0.5763, 0.4518, 0.2881, 0.3646, 0.3824, 0.2776,\n",
      "        0.7297, 0.3744, 0.3061, 0.1861, 0.2541], device='cuda:0')\n",
      " | Test Loss: 1.663 | Test Acc: 50.230\n",
      "\n",
      "=====> Epoch: 43, Loss: 1.662933438639, Acc: 50.230\n",
      "Running Mean: tensor([-0.0780,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0824, -0.0624,  0.0256,  0.0946, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4849, 0.5848, 0.2185, 0.1951, 0.5302, 0.2466, 0.3907, 0.3729, 0.2522,\n",
      "        0.5343, 0.2495, 0.7855, 0.2742, 0.2068, 0.2282, 0.5961, 0.3427, 0.3815,\n",
      "        0.2152, 0.4386, 0.6327, 0.5763, 0.4518, 0.2880, 0.3646, 0.3824, 0.2776,\n",
      "        0.7297, 0.3744, 0.3060, 0.1861, 0.2541], device='cuda:0')\n",
      " | Test Loss: 1.665 | Test Acc: 50.250\n",
      "\n",
      "=====> Epoch: 44, Loss: 1.664868163157, Acc: 50.250\n",
      "Running Mean: tensor([-0.0781,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0940,  0.0824, -0.0624,  0.0256,  0.0945, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0094,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4848, 0.5847, 0.2185, 0.1951, 0.5301, 0.2465, 0.3906, 0.3728, 0.2522,\n",
      "        0.5343, 0.2495, 0.7855, 0.2742, 0.2068, 0.2282, 0.5960, 0.3427, 0.3814,\n",
      "        0.2152, 0.4386, 0.6326, 0.5762, 0.4517, 0.2880, 0.3645, 0.3824, 0.2775,\n",
      "        0.7296, 0.3744, 0.3059, 0.1860, 0.2540], device='cuda:0')\n",
      " | Test Loss: 1.667 | Test Acc: 50.200\n",
      "\n",
      "=====> Epoch: 45, Loss: 1.666619027717, Acc: 50.200\n",
      "Running Mean: tensor([-0.0781,  0.0080, -0.0327,  0.0411,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0939,  0.0824, -0.0624,  0.0256,  0.0945, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0095,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4848, 0.5847, 0.2184, 0.1951, 0.5300, 0.2464, 0.3906, 0.3728, 0.2521,\n",
      "        0.5342, 0.2494, 0.7854, 0.2742, 0.2068, 0.2282, 0.5960, 0.3427, 0.3814,\n",
      "        0.2152, 0.4386, 0.6325, 0.5761, 0.4517, 0.2879, 0.3645, 0.3824, 0.2775,\n",
      "        0.7296, 0.3744, 0.3059, 0.1860, 0.2540], device='cuda:0')\n",
      " | Test Loss: 1.668 | Test Acc: 50.150\n",
      "\n",
      "=====> Epoch: 46, Loss: 1.668202561668, Acc: 50.150\n",
      "Running Mean: tensor([-0.0781,  0.0080, -0.0327,  0.0412,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0596,\n",
      "         0.0555,  0.0939,  0.0824, -0.0624,  0.0256,  0.0945, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0095,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4848, 0.5847, 0.2184, 0.1952, 0.5299, 0.2463, 0.3905, 0.3728, 0.2521,\n",
      "        0.5342, 0.2494, 0.7853, 0.2742, 0.2069, 0.2281, 0.5959, 0.3427, 0.3813,\n",
      "        0.2152, 0.4386, 0.6324, 0.5761, 0.4517, 0.2879, 0.3645, 0.3824, 0.2775,\n",
      "        0.7296, 0.3744, 0.3059, 0.1860, 0.2540], device='cuda:0')\n",
      " | Test Loss: 1.670 | Test Acc: 50.150\n",
      "\n",
      "=====> Epoch: 47, Loss: 1.669634336158, Acc: 50.150\n",
      "Running Mean: tensor([-0.0781,  0.0080, -0.0327,  0.0412,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0597,\n",
      "         0.0555,  0.0939,  0.0824, -0.0624,  0.0256,  0.0945, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0095,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4847, 0.5846, 0.2184, 0.1952, 0.5299, 0.2462, 0.3905, 0.3728, 0.2521,\n",
      "        0.5341, 0.2494, 0.7853, 0.2742, 0.2069, 0.2281, 0.5959, 0.3427, 0.3813,\n",
      "        0.2152, 0.4386, 0.6324, 0.5760, 0.4517, 0.2878, 0.3645, 0.3824, 0.2774,\n",
      "        0.7296, 0.3744, 0.3058, 0.1860, 0.2539], device='cuda:0')\n",
      " | Test Loss: 1.671 | Test Acc: 50.140\n",
      "\n",
      "=====> Epoch: 48, Loss: 1.670928120613, Acc: 50.140\n",
      "Running Mean: tensor([-0.0781,  0.0080, -0.0327,  0.0412,  0.0031, -0.0278, -0.0203,  0.1007,\n",
      "        -0.0345,  0.1536, -0.0707, -0.0159, -0.0274, -0.0073, -0.0186, -0.0597,\n",
      "         0.0555,  0.0939,  0.0824, -0.0624,  0.0256,  0.0945, -0.0898,  0.0672,\n",
      "         0.0513,  0.0673,  0.0002, -0.0095,  0.0843, -0.0914,  0.0443,  0.0962],\n",
      "       device='cuda:0') Running Var: tensor([0.4847, 0.5846, 0.2183, 0.1952, 0.5298, 0.2462, 0.3905, 0.3727, 0.2521,\n",
      "        0.5341, 0.2494, 0.7853, 0.2742, 0.2069, 0.2281, 0.5958, 0.3427, 0.3812,\n",
      "        0.2152, 0.4385, 0.6323, 0.5760, 0.4517, 0.2878, 0.3645, 0.3824, 0.2774,\n",
      "        0.7296, 0.3744, 0.3058, 0.1860, 0.2539], device='cuda:0')\n",
      " | Test Loss: 1.672 | Test Acc: 50.140\n",
      "\n",
      "=====> Epoch: 49, Loss: 1.672096569327, Acc: 50.140\n"
     ]
    }
   ],
   "source": [
    "# get di images from random models\n",
    "inv_batchsize = 10\n",
    "all_inv_image = []\n",
    "for device in round_devices:\n",
    "    if not 'random_model_bn_track' in device:\n",
    "        device['random_model_bn_track'] = model.ConvNet().cuda()\n",
    "        update_bn_only(device, epoch=50)\n",
    "        \n",
    "    di= DeepInversionClass(bs=inv_batchsize, net_teacher=device['random_model_bn_track'], path='./test')\n",
    "    inv_image, inv_target = di.get_images(net_student=None, \n",
    "                                          reset_inputs=True, reset_targets=True, reset_opt=True, iterations_per_layer=4000)\n",
    "    device['inv_image'] = inv_image\n",
    "    all_inv_image.append(inv_image)\n",
    "    \n",
    "all_inv_image_tensor = torch.cat(all_inv_image)\n",
    "\n",
    "\n",
    "\n",
    "# finetune on the inversed images\n",
    "net_invbn = copy.deepcopy(net)\n",
    "net_invbn.load_state_dict(new_w_avg)\n",
    "invbn_device = {'net': net_invbn, 'test_loss_tracker':[], 'test_acc_tracker':[]}\n",
    "show_bn(net_invbn)\n",
    "test_loss, test_acc = test(0, invbn_device, False)\n",
    "print('=====> Start Check, Loss: %.12f, Acc: %.3f'%(test_loss, test_acc))\n",
    "\n",
    "\n",
    "## Update the running mean and running variance\n",
    "invbn_epochs = 50\n",
    "\n",
    "\n",
    "for epoch_idx in range(invbn_epochs):\n",
    "    invbn_device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    # inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs = all_inv_image_tensor\n",
    "    outputs = invbn_device['net'](inputs)\n",
    "    # loss = criterion(outputs, targets)\n",
    "    # train_loss += loss.item()\n",
    "    # loss = train_loss / (batch_idx + 1)\n",
    "    # _, predicted = outputs.max(1)\n",
    "    # total += targets.size(0)\n",
    "    # correct += predicted.eq(targets).sum().item()\n",
    "    # acc = 100. * correct / total\n",
    "    # if batch_idx%100==0:\n",
    "    #     print('Debias finetune on Train| Epoch: %d | Loss: %.6f, Acc: %.2f'%(epoch_idx, loss, acc))\n",
    "\n",
    "    show_bn(invbn_device['net'])\n",
    "    test_loss, test_acc = test(0, invbn_device, False)\n",
    "    print('=====> Epoch: %d, Loss: %.12f, Acc: %.3f'%(epoch_idx, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get di images\n",
    "inv_batchsize = 10\n",
    "all_inv_image = []\n",
    "for device in round_devices:\n",
    "    di= DeepInversionClass(bs=inv_batchsize, net_teacher=device['net'], path='./test')\n",
    "    inv_image, inv_target = di.get_images(net_student=None, \n",
    "                                          reset_inputs=True, reset_targets=True, reset_opt=True)\n",
    "    device['inv_image'] = inv_image\n",
    "    all_inv_image.append(inv_image)\n",
    "    \n",
    "all_inv_image_tensor = torch.cat(all_inv_image)\n",
    "\n",
    "\n",
    "\n",
    "# finetune on the inversed images\n",
    "net_invbn = copy.deepcopy(net)\n",
    "net_invbn.load_state_dict(new_w_avg)\n",
    "invbn_device = {'net': net_invbn, 'test_loss_tracker':[], 'test_acc_tracker':[]}\n",
    "show_bn(net_invbn)\n",
    "test_loss, test_acc = test(0, invbn_device, False)\n",
    "print('=====> Start Check, Loss: %.12f, Acc: %.3f'%(test_loss, test_acc))\n",
    "\n",
    "\n",
    "## Update the running mean and running variance\n",
    "invbn_epochs = 50\n",
    "\n",
    "\n",
    "for epoch_idx in range(invbn_epochs):\n",
    "    invbn_device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    # inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs = all_inv_image_tensor\n",
    "    outputs = invbn_device['net'](inputs)\n",
    "    # loss = criterion(outputs, targets)\n",
    "    # train_loss += loss.item()\n",
    "    # loss = train_loss / (batch_idx + 1)\n",
    "    # _, predicted = outputs.max(1)\n",
    "    # total += targets.size(0)\n",
    "    # correct += predicted.eq(targets).sum().item()\n",
    "    # acc = 100. * correct / total\n",
    "    # if batch_idx%100==0:\n",
    "    #     print('Debias finetune on Train| Epoch: %d | Loss: %.6f, Acc: %.2f'%(epoch_idx, loss, acc))\n",
    "\n",
    "    show_bn(invbn_device['net'])\n",
    "    test_loss, test_acc = test(0, invbn_device, False)\n",
    "    print('=====> Epoch: %d, Loss: %.12f, Acc: %.3f'%(epoch_idx, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get di images\n",
    "inv_batchsize = 10\n",
    "all_inv_image = []\n",
    "for device in round_devices:\n",
    "    di= DeepInversionClass(bs=inv_batchsize, net_teacher=device['net'], path='./test')\n",
    "    inv_image, inv_target = di.get_images(net_student=None, \n",
    "                                          reset_inputs=True, reset_targets=True, reset_opt=True, quant_input=True)\n",
    "    device['inv_image'] = inv_image\n",
    "    all_inv_image.append(inv_image)\n",
    "    \n",
    "all_inv_image_tensor = torch.cat(all_inv_image)\n",
    "\n",
    "\n",
    "\n",
    "# finetune on the inversed images\n",
    "net_invbn = copy.deepcopy(net)\n",
    "net_invbn.load_state_dict(new_w_avg)\n",
    "invbn_device = {'net': net_invbn, 'test_loss_tracker':[], 'test_acc_tracker':[]}\n",
    "show_bn(net_invbn)\n",
    "test_loss, test_acc = test(0, invbn_device, False)\n",
    "print('=====> Start Check, Loss: %.12f, Acc: %.3f'%(test_loss, test_acc))\n",
    "\n",
    "\n",
    "## Update the running mean and running variance\n",
    "invbn_epochs = 50\n",
    "\n",
    "\n",
    "for epoch_idx in range(invbn_epochs):\n",
    "    invbn_device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    # inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs = all_inv_image_tensor\n",
    "    outputs = invbn_device['net'](inputs)\n",
    "    # loss = criterion(outputs, targets)\n",
    "    # train_loss += loss.item()\n",
    "    # loss = train_loss / (batch_idx + 1)\n",
    "    # _, predicted = outputs.max(1)\n",
    "    # total += targets.size(0)\n",
    "    # correct += predicted.eq(targets).sum().item()\n",
    "    # acc = 100. * correct / total\n",
    "    # if batch_idx%100==0:\n",
    "    #     print('Debias finetune on Train| Epoch: %d | Loss: %.6f, Acc: %.2f'%(epoch_idx, loss, acc))\n",
    "\n",
    "    show_bn(invbn_device['net'])\n",
    "    test_loss, test_acc = test(0, invbn_device, False)\n",
    "    print('=====> Epoch: %d, Loss: %.12f, Acc: %.3f'%(epoch_idx, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_num_para_inbn(model):\n",
    "    total_num = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total_num += m.running_mean.nelement()*2\n",
    "    return total_num\n",
    "\n",
    "cal_num_para_inbn(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
